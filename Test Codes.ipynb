{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Don't refer to this notebook. It is only testing purpose of different coding concepts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import math\n",
    "import time\n",
    "from collections import OrderedDict\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"poster\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Motive is to get all the data science jobs from \"https://www.naukri.com\"\n",
    "\n",
    "# Base URL : \"-\" is added to help later while structuring the other pages URL\n",
    "base_url = \"https://www.naukri.com/data-scientist-jobs-\"\n",
    "base_response = requests.get(base_url)\n",
    "base_page = base_response.text\n",
    "\n",
    "# Convert the response to BeautifulSoup object\n",
    "base_soup = BeautifulSoup(base_page, \"html.parser\")\n",
    "\n",
    "# Find the total number of jobs : which is 10043\n",
    "num_jobs = int(base_soup.find(\"div\", { \"class\" : \"count\" }).h1.contents[1].getText().split(' ')[-1])\n",
    "# Each page lists 50 jobs, so total pages\n",
    "num_pages = int(math.ceil(num_jobs/50.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.naukri.com/job-listings-AI-Scientist-Wissen-Infotech-Pvt-Ltd-Bengaluru-Marathahalli-5-to-8-years-111017002270?src=nfl&sid=15082247001086&xp=1',\n",
       " 'https://www.naukri.com/job-listings-Data-Scientist-GoPaisa-Netventures-Pvt-Ltd-New-Delhi-Jasola-3-to-5-years-161017900264?src=jobsearchDesk&sid=15082247001086&xp=2',\n",
       " 'https://www.naukri.com/job-listings-Senior-Data-Scientist-Pricewaterhouse-Coopers-Private-Limited-Delhi-NCR-4-to-7-years-161017006002?src=jobsearchDesk&sid=15082247001086&xp=3',\n",
       " 'https://www.naukri.com/job-listings-Sr-Data-Scientist-Pykih-Data-Intelligence-Private-Limited-Ahmedabad-5-to-10-years-161017005627?src=jobsearchDesk&sid=15082247001086&xp=4',\n",
       " 'https://www.naukri.com/job-listings-Data-Scientist-SQL-Hive-Pig-xtLytics-Delhi-NCR-Noida-5-to-10-years-131017901845?src=jobsearchDesk&sid=15082247001086&xp=5',\n",
       " 'https://www.naukri.com/job-listings-Data-Scientist-It-internet-online-Premium-Delhi-NCR-Gurgaon-5-to-9-years-161017902522?src=jobsearchDesk&sid=15082247001086&xp=6',\n",
       " 'https://www.naukri.com/job-listings-Data-Scientist-R-Statistical-Modelling-IIT-NIT-Kafal-Software-Delhi-NCR-4-to-9-years-131017901840?src=jobsearchDesk&sid=15082247001086&xp=7',\n",
       " 'https://www.naukri.com/job-listings-SDM-BPS-Analytics-data-Scientist-BPO-Premium-Hyderabad-7-to-10-years-161017900934?src=jobsearchDesk&sid=15082247001086&xp=8',\n",
       " 'https://www.naukri.com/job-listings-Senior-Data-Scientist-SAP-India-Pvt-Ltd-Bengaluru-5-to-10-years-121017901778?src=jobsearchDesk&sid=15082247001086&xp=9',\n",
       " 'https://www.naukri.com/job-listings-Data-Scientist-Sr-Level-ICs-ManpowerGroup-Services-India-Private-Limited-Bengaluru-10-to-20-years-300917001477?src=jobsearchDesk&sid=15082247001086&xp=10',\n",
       " 'https://www.naukri.com/job-listings-Data-Scientist-Nlp-big-Data-spark-ColorTokens-Inc-Bengaluru-7-to-10-years-121017900911?src=jobsearchDesk&sid=15082247001086&xp=11',\n",
       " 'https://www.naukri.com/job-listings-Principal-Data-Scientist-IIT-NIT-CA-India-Technologies-Private-Limited-Hyderabad-7-to-12-years-111017002473?src=jobsearchDesk&sid=15082247001086&xp=12',\n",
       " 'https://www.naukri.com/job-listings-Analyst-Data-Scientist-Insurance-1-4-5-Years-Crescendo-Global-Services-Mumbai-1-to-5-years-141017002596?src=jobsearchDesk&sid=15082247001086&xp=13',\n",
       " 'https://www.naukri.com/job-listings-Opening-for-Data-Scientist-sr-data-Analyst-Gurgaon-Boston-Software-Consultants-India-Pvt-Ltd-Gurgaon-5-to-10-years-101017006341?src=jobsearchDesk&sid=15082247001086&xp=14',\n",
       " 'https://www.naukri.com/job-listings-Data-Scientist-Global-Artificial-Intelligence-Company-Bangalore-Unnati-Bengaluru-3-to-7-years-101017004015?src=jobsearchDesk&sid=15082247001086&xp=15',\n",
       " 'https://www.naukri.com/job-listings-Lennox-is-Hiring-Data-Scientist-Chennai-Location-Lennox-India-Technology-Centre-Private-Limited-Chennai-8-to-13-years-190717002494?src=jobsearchDesk&sid=15082247001086&xp=16',\n",
       " 'https://www.naukri.com/job-listings-Senior-Data-Scientist-Bundl-Technologies-Pvt-Ltd-Bengaluru-3-to-6-years-131017900903?src=jobsearchDesk&sid=15082247001086&xp=17',\n",
       " 'https://www.naukri.com/job-listings-Data-Scientist-IBM-India-Pvt-Limited-Bengaluru-3-to-6-years-111017900841?src=jobsearchDesk&sid=15082247001086&xp=18',\n",
       " 'https://www.naukri.com/job-listings-Senior-Data-Scientist-Text-Mining-Molecular-connections-Bengaluru-4-to-5-years-111017900528?src=jobsearchDesk&sid=15082247001086&xp=19',\n",
       " 'https://www.naukri.com/job-listings-Data-Scientist-Requirement-for-Pune-L-T-Infotech-Larsen-Toubro-Infotech-Limited-Pune-7-to-11-years-111017004506?src=jobsearchDesk&sid=15082247001086&xp=20',\n",
       " 'https://www.naukri.com/job-listings-Data-Scientist-Python-BFS-HuQuo-Delhi-NCR-Gurgaon-2-to-5-years-101017901328?src=jobsearchDesk&sid=15082247001086&xp=21',\n",
       " 'https://www.naukri.com/job-listings-Data-Scientist-Xebia-IT-Architects-India-Pvt-Ltd-Bengaluru-8-to-10-years-101017900245?src=jobsearchDesk&sid=15082247001086&xp=22',\n",
       " 'https://www.naukri.com/job-listings-Data-Scientist-DECISIVEDGE-TECHNOLOGY-SERVICES-INDIA-PVT-LTD-Pune-2-to-4-years-101017001762?src=jobsearchDesk&sid=15082247001086&xp=23',\n",
       " 'https://www.naukri.com/job-listings-Lead-Data-Scientist-Accenture-Solutions-Pvt-Ltd-Bengaluru-4-to-9-years-091017003692?src=jobsearchDesk&sid=15082247001086&xp=24',\n",
       " 'https://www.naukri.com/job-listings-Unify-Urgent-Requirement-Data-Scientist-Gurugram-UNIFY-TECHNOLOGIES-PVT-LTD-Gurgaon-2-to-6-years-070817000721?src=jobsearchDesk&sid=15082247001086&xp=25',\n",
       " 'https://www.naukri.com/job-listings-Data-Scientist-Applexus-Technologies-P-Ltd-Trivandrum-1-to-5-years-061017006900?src=jobsearchDesk&sid=15082247001086&xp=26',\n",
       " 'https://www.naukri.com/job-listings-Urgently-Hiring-for-Data-Scientist-Bebo-Technologies-Pvt-Ltd-Chandigarh-4-to-8-years-121017006738?src=jobsearchDesk&sid=15082247001086&xp=27',\n",
       " 'https://www.naukri.com/job-listings-Looking-for-a-Data-Scientist-Role-Accenture-Solutions-Pvt-Ltd-Gurgaon-12-to-16-years-121017003370?src=jobsearchDesk&sid=15082247001086&xp=28',\n",
       " 'https://www.naukri.com/job-listings-Data-Scientist-Enterprise-Cloud-Security-Platform-People-Gamut-HR-Solutions-Bengaluru-Pune-5-to-8-years-101017003114?src=jobsearchDesk&sid=15082247001086&xp=29',\n",
       " 'https://www.naukri.com/job-listings-Data-Scientist-Signal-Processing-Engineer-Nanoprecise-Sci-Corp-Bengaluru-Electronic-City-1-2-to-5-years-101017000085?src=jobsearchDesk&sid=15082247001086&xp=30',\n",
       " 'https://www.naukri.com/job-listings-Data-Scientist-Decision-Minds-India-P-Ltd-Chennai-5-to-10-years-060617003796?src=jobsearchDesk&sid=15082247001086&xp=31',\n",
       " 'https://www.naukri.com/job-listings-Opening-for-Data-Scientist-Position-Analytics-Firm-Bengaluru-2-to-7-years-041017006554?src=jobsearchDesk&sid=15082247001086&xp=32',\n",
       " 'https://www.naukri.com/job-listings-Artificial-Intelligence-Specialist-data-Scientist-associate-Principal-Accenture-Solutions-Pvt-Ltd-Bengaluru-5-to-10-years-121017002936?src=jobsearchDesk&sid=15082247001086&xp=33',\n",
       " 'https://www.naukri.com/job-listings-Data-Scientist-Sas-sql-spss-Talpro-Delhi-NCR-Bengaluru-8-to-12-years-241016900804?src=jobsearchDesk&sid=15082247001086&xp=34',\n",
       " 'https://www.naukri.com/job-listings-Data-Scientist-Sas-sql-spss-Talpro-Delhi-NCR-Bengaluru-8-to-12-years-240816901314?src=jobsearchDesk&sid=15082247001086&xp=35',\n",
       " 'https://www.naukri.com/job-listings-Data-Scientist-Sas-sql-spss-TalPro-Delhi-NCR-Bengaluru-8-to-12-years-210915901140?src=jobsearchDesk&sid=15082247001086&xp=36',\n",
       " 'https://www.naukri.com/job-listings-Urgent-Requirement-for-a-Data-Scientist-M-S-Myriad-Consuting-Navi-Mumbai-2-to-5-years-131017003642?src=jobsearchDesk&sid=15082247001086&xp=37',\n",
       " 'https://www.naukri.com/job-listings-Opportunity-for-Principal-Data-Scientist-with-Nouveau-Labs-FloLearning-Solutions-Pvt-Ltd-Bengaluru-10-to-20-years-131017003465?src=jobsearchDesk&sid=15082247001086&xp=38',\n",
       " 'https://www.naukri.com/job-listings-Opportunity-for-Principal-Data-Scientist-with-Nouveau-Labs-FloLearning-Solutions-Pvt-Ltd-Bengaluru-10-to-20-years-131017003309?src=jobsearchDesk&sid=15082247001086&xp=39',\n",
       " 'https://www.naukri.com/job-listings-Software-Engineer-data-Scientist-Client-Of-Sampoorna-Mumbai-2-to-5-years-121017901025?src=jobsearchDesk&sid=15082247001086&xp=40',\n",
       " 'https://www.naukri.com/job-listings-Data-Scientist-KPO-Premium-Chennai-3-to-8-years-121017900418?src=jobsearchDesk&sid=15082247001086&xp=41',\n",
       " 'https://www.naukri.com/job-listings-Senior-Data-Scientist-KPO-Premium-Chennai-5-to-10-years-121017900417?src=jobsearchDesk&sid=15082247001086&xp=42',\n",
       " 'https://www.naukri.com/job-listings-Data-Scientist-senior-Data-Scientist-Advanced-Analytics-Consulting-F-Premium-Chennai-3-to-8-years-121017900413?src=jobsearchDesk&sid=15082247001086&xp=43',\n",
       " 'https://www.naukri.com/job-listings-Data-Scientist-Analytics-Firm-Premium-Mumbai-2-to-7-years-121017900371?src=jobsearchDesk&sid=15082247001086&xp=44',\n",
       " 'https://www.naukri.com/job-listings-Senior-Reporting-Analyst-Data-Scientist-Consulting-Firm-Premium-Chennai-3-to-6-years-121017900359?src=jobsearchDesk&sid=15082247001086&xp=45',\n",
       " 'https://www.naukri.com/job-listings-Data-Scientist-Digital-Intelligence-COE-Courier-Services-Premium-Mumbai-2-to-7-years-121017900183?src=jobsearchDesk&sid=15082247001086&xp=46',\n",
       " 'https://www.naukri.com/job-listings-Data-Scientist-ETL-Analytics-Premium-Mumbai-3-to-6-years-111017901148?src=jobsearchDesk&sid=15082247001086&xp=47',\n",
       " 'https://www.naukri.com/job-listings-Manager-senior-Manager-Cyber-Security-Data-Scientist-Premium-Mumbai-6-to-11-years-111017901098?src=jobsearchDesk&sid=15082247001086&xp=48',\n",
       " 'https://www.naukri.com/job-listings-Data-Scientist-R-nlp-data-Mining-Premium-Bengaluru-10-to-12-years-101017900281?src=jobsearchDesk&sid=15082247001086&xp=49',\n",
       " 'https://www.naukri.com/job-listings-Data-Scientist-R-Python-with-Machine-Learning-Expert-Pune-Mississippi-Consultants-Pune-5-to-10-years-080917006060?src=jobsearchDesk&sid=15082247001086&xp=50',\n",
       " 'https://www.naukri.com/job-listings-Data-Scientist-SAS-SQL-SPSS-TalPro-Bengaluru-Delhi-NCR-8-to-12-years-180216900301?src=jobsearchDesk&sid=15082247001086&xp=51',\n",
       " 'https://www.naukri.com/job-listings-Data-Scientist-NLP-Data-Modeling-Premium-Mumbai-1-to-5-years-101017900272?src=jobsearchDesk&sid=15082247017514&xp=1',\n",
       " 'https://www.naukri.com/job-listings-Urgent-Opening-for-DATA-Scientist-Sutherland-Bangalore-Sutherland-Global-Services-Private-Limited-Bengaluru-4-to-6-years-111017006218?src=jobsearchDesk&sid=15082247017514&xp=2',\n",
       " 'https://www.naukri.com/job-listings-Data-Scientist-machine-Learning-Skill-Required-Tokyo-Japan-Port-Japan-Tokyo-Japan-3-to-8-years-101017001109?src=jobsearchDesk&sid=15082247017514&xp=3',\n",
       " 'https://www.naukri.com/job-listings-Data-Scientist-Bebo-Technologies-Pvt-Ltd-Chandigarh-4-to-7-years-101017002166?src=jobsearchDesk&sid=15082247017514&xp=4',\n",
       " 'https://www.naukri.com/job-listings-Data-Scientist-R-python-machine-Learning-Premium-Bengaluru-2-to-4-years-111017901620?src=jobsearchDesk&sid=15082247017514&xp=5',\n",
       " 'https://www.naukri.com/job-listings-Deep-Learning-Engineer-Data-Scientist-SAP-India-Pvt-Ltd-Bengaluru-4-to-8-years-310817900433?src=jobsearchDesk&sid=15082247017514&xp=6',\n",
       " 'https://www.naukri.com/job-listings-Data-Scientist-Role-Market-Research-Domain-at-MNC-Chennai-Golden-Opportunities-Pvt-Ltd-Chennai-5-to-7-years-101017002088?src=jobsearchDesk&sid=15082247017514&xp=7',\n",
       " 'https://www.naukri.com/job-listings-Senior-Data-Scientist-Cactus-Communications-Pvt-Ltd-Mumbai-2-to-7-years-220917007027?src=jobsearchDesk&sid=15082247017514&xp=8',\n",
       " 'https://www.naukri.com/job-listings-Con-AM-Data-Scientist-Pylon-Management-Consulting-Pvt-Ltd-Bengaluru-5-to-10-years-070716000235?src=jobsearchDesk&sid=15082247017514&xp=9',\n",
       " 'https://www.naukri.com/job-listings-Research-Engineer-data-Scientist-Morningstar-India-P-Ltd-Mumbai-3-to-6-years-140917003438?src=jobsearchDesk&sid=15082247017514&xp=10',\n",
       " 'https://www.naukri.com/job-listings-Data-Scientist-Crescendo-Global-Services-Mumbai-Chennai-4-to-9-years-141017000938?src=jobsearchDesk&sid=15082247017514&xp=11',\n",
       " 'https://www.naukri.com/job-listings-Senior-Data-Scientist-Verint-Systems-India-Pvt-Ltd-Bengaluru-2-to-7-years-070917901451?src=jobsearchDesk&sid=15082247017514&xp=12',\n",
       " 'https://www.naukri.com/job-listings-Senior-Manager-Manager-Data-Scientist-Crescendo-Global-Services-Mumbai-3-to-8-years-141017001537?src=jobsearchDesk&sid=15082247017514&xp=13',\n",
       " 'https://www.naukri.com/job-listings-Urgent-Opening-For-Software-Engineer-data-Scientist-for-MNC-Mumbai-Amal-Info-System-Pvt-ltd-Mumbai-3-to-7-years-141017000707?src=jobsearchDesk&sid=15082247017514&xp=14',\n",
       " 'https://www.naukri.com/job-listings-Manager-Data-Scientist-for-an-Internet-Company-Talentfair-Consultancy-Private-Limited-Mumbai-Tardeo-3-to-8-years-111017006409?src=jobsearchDesk&sid=15082247017514&xp=15',\n",
       " 'https://www.naukri.com/job-listings-Hiring-For-Data-Scientist-New-Horizons-Noida-Sector-3-Noida-3-to-8-years-111017003511?src=jobsearchDesk&sid=15082247017514&xp=16',\n",
       " 'https://www.naukri.com/job-listings-DATA-Scientist-Required-EXP-ON-SAS-Python-R-AI-ML-NLP-IN-Gurgaon-Hire-Q-Consulting-Gurgaon-3-to-7-years-141017003500?src=jobsearchDesk&sid=15082247017514&xp=17',\n",
       " 'https://www.naukri.com/job-listings-Hiring-for-Data-Scientist-Hyderabad-Live-connections-Hyderabad-4-to-6-years-101017004606?src=jobsearchDesk&sid=15082247017514&xp=18',\n",
       " 'https://www.naukri.com/job-listings-Principal-Research-Scientist-Data-Mining-Premium-Bengaluru-10-to-18-years-141017000457?src=jobsearchDesk&sid=15082247017514&xp=19',\n",
       " 'https://www.naukri.com/job-listings-Principal-Research-Scientist-Data-Analytics-Premium-Bengaluru-10-to-18-years-141017000455?src=jobsearchDesk&sid=15082247017514&xp=20',\n",
       " 'https://www.naukri.com/job-listings-Machine-Learning-Scientist-Data-Mining-nlp-Premium-Bengaluru-5-to-10-years-111017900543?src=jobsearchDesk&sid=15082247017514&xp=21',\n",
       " 'https://www.naukri.com/job-listings-Data-Analyst-scientist-Energy-Utility-Development-Group-Premium-Delhi-NCR-Gurgaon-5-to-10-years-111017901089?src=jobsearchDesk&sid=15082247017514&xp=22',\n",
       " 'https://www.naukri.com/job-listings-Senior-Scientist-Machine-Learning-data-Modeling-Premium-Bengaluru-5-to-10-years-111017900541?src=jobsearchDesk&sid=15082247017514&xp=23',\n",
       " 'https://www.naukri.com/job-listings-Urgent-Hiring-data-Scientist-analyst-bangalore-Permanent-JConnect-Infotech-Private-Limited-Bengaluru-8-to-13-years-250917000758?src=jobsearchDesk&sid=15082247017514&xp=24',\n",
       " 'https://www.naukri.com/job-listings-Data-Scientist-Analyst-Adoro-Startup-Mumbai-2-to-5-years-210917900808?src=jobsearchDesk&sid=15082247017514&xp=25',\n",
       " 'https://www.naukri.com/job-listings-Data-Scientist-Manager-Analytics-Coverfox-Insurance-Broking-Pvt-Ltd-Mumbai-Saki-Vihar-Mumbai-Suburbs-4-to-6-years-040917005889?src=jobsearchDesk&sid=15082247017514&xp=26',\n",
       " 'https://www.naukri.com/job-listings-Data-Scientist-Aniaaz-Consulting-Private-Limited-Chennai-2-to-4-years-041017001844?src=jobsearchDesk&sid=15082247017514&xp=27',\n",
       " 'https://www.naukri.com/job-listings-Data-Scientist-data-Analyst-semanticHR-advisors-and-consultants-pvt-ltd-Germany-8-to-12-years-061017007015?src=jobsearchDesk&sid=15082247017514&xp=28',\n",
       " 'https://www.naukri.com/job-listings-Data-Scientist-CONFIDENTIAL-Bengaluru-6-to-10-years-271216901589?src=jobsearchDesk&sid=15082247017514&xp=29',\n",
       " 'https://www.naukri.com/job-listings-Hiring-for-Data-Scientist-7-12-Yrs-Permanent-Bangalore-JConnect-Infotech-Private-Limited-Bengaluru-7-to-12-years-250917000688?src=jobsearchDesk&sid=15082247017514&xp=30',\n",
       " 'https://www.naukri.com/job-listings-Senior-Data-Scientist-ZS-ZS-ASSOCIATES-Pune-Gurgaon-4-to-9-years-120916003586?src=jobsearchDesk&sid=15082247017514&xp=31',\n",
       " 'https://www.naukri.com/job-listings-Data-Scientist-Big-Data-IDS-Infotech-Ltd-Chandigarh-Mohali-3-to-8-years-100717005034?src=jobsearchDesk&sid=15082247017514&xp=32',\n",
       " 'https://www.naukri.com/job-listings-Data-Scientist-Pensieve-Startup-Mumbai-5-to-10-years-091017900491?src=jobsearchDesk&sid=15082247017514&xp=33',\n",
       " 'https://www.naukri.com/job-listings-Senior-Data-Scientist-Yodlee-Infotech-Private-Limited-Bengaluru-7-to-12-years-091017006886?src=jobsearchDesk&sid=15082247017514&xp=34',\n",
       " 'https://www.naukri.com/job-listings-Data-Scientist-EYGBS-India-Private-Limited-Trivandrum-5-to-10-years-091017005966?src=jobsearchDesk&sid=15082247017514&xp=35',\n",
       " 'https://www.naukri.com/job-listings-Data-Scientist-Machine-Learning-nlp-Enterprise-Bot-Startup-Bengaluru-2-to-7-years-061017901247?src=jobsearchDesk&sid=15082247017514&xp=36',\n",
       " 'https://www.naukri.com/job-listings-Senior-Data-Scientist-gNxt-Systems-Noida-4-to-6-years-061017900754?src=jobsearchDesk&sid=15082247017514&xp=37',\n",
       " 'https://www.naukri.com/job-listings-Data-Scientist-Artificial-Intelligence-machine-Learning-Startup-ZipGo-Technologies-Pvt-Ltd-Bengaluru-2-to-5-years-061017900119?src=jobsearchDesk&sid=15082247017514&xp=38',\n",
       " 'https://www.naukri.com/job-listings-Senior-Data-Scientist-Nivaata-Systems-Startup-Bengaluru-2-to-5-years-061017900103?src=jobsearchDesk&sid=15082247017514&xp=39',\n",
       " 'https://www.naukri.com/job-listings-Junior-Data-Science-Scientist-Senior-Data-Scientist-Cloudbyte-Startup-Bengaluru-3-to-8-years-061017900019?src=jobsearchDesk&sid=15082247017514&xp=40',\n",
       " 'https://www.naukri.com/job-listings-Data-Scientist-Digital-Intelligence-COE-FedEX-Express-Transportation-Supply-ChainServices-I-Pvt-Ltd-Mumbai-2-to-7-years-060917003158?src=jobsearchDesk&sid=15082247017514&xp=41',\n",
       " 'https://www.naukri.com/job-listings-Data-Scientist-Online-Retail-Domain-Mindaquest-Business-Solution-Pvt-Ltd-Delhi-NCR-Bengaluru-5-to-10-years-051017900037?src=jobsearchDesk&sid=15082247017514&xp=42',\n",
       " 'https://www.naukri.com/job-listings-Data-Scientist-Online-Retail-Domain-Mindaquest-Business-Solution-Pvt-Ltd-Delhi-NCR-Bengaluru-5-to-10-years-041017901331?src=jobsearchDesk&sid=15082247017514&xp=43',\n",
       " 'https://www.naukri.com/job-listings-Data-Scientist-Machine-Learning-Deep-Learning-Mindaquest-Business-Solution-Pvt-Ltd-Delhi-NCR-3-to-6-years-041017901329?src=jobsearchDesk&sid=15082247017514&xp=44',\n",
       " 'https://www.naukri.com/job-listings-Data-Scientist-Product-Startup-IIT-BITS-NIT-IIIT-Houm-Mumbai-2-to-4-years-041017901148?src=jobsearchDesk&sid=15082247017514&xp=45',\n",
       " 'https://www.naukri.com/job-listings-Data-Scientist-Sagacito-Technologies-Delhi-NCR-2-to-7-years-041017900197?src=jobsearchDesk&sid=15082247017514&xp=46',\n",
       " 'https://www.naukri.com/job-listings-Data-Scientist-for-a-US-Based-Product-MNC-Careernet-Technologies-Pvt-Ltd-Bengaluru-7-to-10-years-040917005532?src=jobsearchDesk&sid=15082247017514&xp=47',\n",
       " 'https://www.naukri.com/job-listings-Hiring-For-Data-Scientist-7-yrs-Permanent-Bangalore-JConnect-Infotech-Private-Limited-Bengaluru-7-to-12-years-031017006007?src=jobsearchDesk&sid=15082247017514&xp=48',\n",
       " 'https://www.naukri.com/job-listings-Data-Scientist-NALCO-WATER-INDIA-LIMITED-Pune-1-to-5-years-031017005225?src=jobsearchDesk&sid=15082247017514&xp=49',\n",
       " 'https://www.naukri.com/job-listings-Data-Scientist-Python-r-Premium-Mumbai-2-to-5-years-121017900047?src=jobsearchDesk&sid=15082247017514&xp=50']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all the job links, each page have 50 job links\n",
    "# pattern in page url is - https://www.naukri.com/data-scientist-jobs-page_number\n",
    "\n",
    "# Create a empty list to store all job links\n",
    "job_links = []\n",
    "\n",
    "# Want to scrap in a gap, so that I don't overload there server\n",
    "req_page = 20\n",
    "# keep changing the start_ind\n",
    "start_ind = 1\n",
    "end_ind = start_ind + req_page\n",
    "\n",
    "# For loop to get link from each of num_pages\n",
    "# To run in a single loop USE : range(1, num_pages+1)\n",
    "for page in range(start_ind, end_ind):\n",
    "    # structuring the page URL\n",
    "    page_url = base_url + str(page)\n",
    "    page_response = requests.get(page_url)\n",
    "    page_txt = page_response.text\n",
    "    page_soup = BeautifulSoup(page_txt, \"html.parser\")\n",
    "    # 50 job links are in the class content, so filtering only content class\n",
    "    links = [l.get(\"href\") for l in page_soup.find_all(\"a\", {\"class\":\"content\"})]\n",
    "    # Append the links into job_links\n",
    "    #for pl in links:\n",
    "        #job_links.append(pl)\n",
    "    \n",
    "job_links\n",
    "\n",
    "# All together : FIND BELOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through each job URL\n",
    "lti = \"https://www.naukri.com/job-listings-Data-Scientist-Requirement-for-Pune-L-T-Infotech-Larsen-Toubro-Infotech-Limited-Pune-7-to-11-years-111017004506\"\n",
    "pwc = \"https://www.naukri.com/job-listings-Senior-Data-Scientist-Pricewaterhouse-Coopers-Private-Limited-Delhi-NCR-4-to-7-years-161017006002\"\n",
    "job_url = lti\n",
    "job_response = requests.get(job_url)\n",
    "job_page = job_response.text\n",
    "job_soup = BeautifulSoup(job_page, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a class=\"fr mt5\" href=\"javascript:void(0);\" id=\"srfClose\" onclick=\"hidemodal();\" title=\"Close\"><span class=\"crossLB\">Â </span></a>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_soup.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Data Scientist Requirement for Pune L&T; Infotech'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_title = job_soup.find(\"h1\", {\"title\":\"jobTitleHeading\"}).getText().strip()\n",
    "job_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Scientist Requirement for Pune L&T; Infotech\n"
     ]
    }
   ],
   "source": [
    "if job_soup.find(\"h1\", {\"title\":\"jobTitleHeading\"}) is None:\n",
    "    print(\"ab\")\n",
    "else:\n",
    "    print(job_soup.find(\"h1\", {\"title\":\"jobTitleHeading\"}).getText().strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ab\n"
     ]
    }
   ],
   "source": [
    "if job_soup.find(\"a\",{\"itemprop\":\"hiringOrganization\"}) is None:\n",
    "    print(\"ab\")\n",
    "else:\n",
    "    print(job_soup.find(\"a\",{\"itemprop\":\"hiringOrganization\"}).getText().strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LARSEN & TOUBRO INFOTECH LIMITED'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_soup.find(\"a\", {\"class\":\"logo fl\"}).get(\"title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'7 - 11 Years'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experience = job_soup.find(\"p\",{\"class\":\"lh20 txtAlgLf\"}).contents[0].getText().strip()\n",
    "experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Pune'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "location = job_soup.find(\"span\",{\"class\":\"fl disc-li\"}).getText().strip()\n",
    "location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Not Disclosed by Recruiter'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salary = job_soup.find(\"span\",{\"class\":\"sal\"}).getText().strip()\n",
    "salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# openings = job_soup.find(\"div\",{\"class\":\"sumFoot\"}).find_all(\"span\")\n",
    "# openings\n",
    "openings = \"\"\n",
    "posted = \"\"\n",
    "for x in job_soup.find(\"div\",{\"class\":\"sumFoot\"}).find_all(\"span\"):\n",
    "    if \"Openings\" in x.text.strip():\n",
    "        openings = x.text.strip()\n",
    "    if \"Posted\" in x.text.strip():\n",
    "        posted = x.text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'88'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_application = job_soup.find(\"span\",{\"class\":\"jApplys\"}).find(\"strong\").getText().strip()\n",
    "job_application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Posted: 7 days ago\n"
     ]
    }
   ],
   "source": [
    "print(openings)\n",
    "print(posted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'81'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_view = job_soup.find(\"span\",{\"class\":\"jViews\"}).find(\"strong\").getText().strip()\n",
    "job_view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'HI,     Greetings for LTI.     We have urgent requirement for Data Scientist.     Here is the JD     JD of Data Scientist Experience -7-11 years Location - Pune \\tHands on experience in build and deployment of Statistical Models/Machine Learning using  following techniques  Statistical Algorithms (preferred in sequence) (Good to have) o\\tSegmentation (Cluster Analysis) o\\tExploratory Analytics (T-tests) o\\tMultivariate Regression (Logistic, OLS, GLM etc.) o\\tDecision Trees o\\tTime series & Non Linear Modeling o\\tRandom Forest o\\tNeural Network \\tExperience with SQL preferred o\\tTraditional DBs  Oracle, TD, Sybase, MS SQL, Win SQL \\tAny of the Big Data querying language (Hive, PIG, Hadoop, etc.) (Good to have) \\tExperience using digital & statistical modeling software (one or more)  o\\tR, Revo R (Preferred) o\\tSAS Basic & Enterprise Miner (Preferred) o\\tSQL (Preferred) o\\tSPSS \\tAbility of Visual story-telling with BI & Visualisation Tools (Tableau, PowerBI, Kibana) is preferred. \\tAdvanced Excel and PowerPoint skills \\tConsulting skills Experience preferred \\tExcellent written and oral communication skills with ability to clearly communicate ideas and results to non-technical business people \\tSelf-Starter with ability to work independently across multiple projects and set priorities \\tWillingness to work at client location  \\n\\r\\n\\t\\t\\tSalary:                Not Disclosed by Recruiter\\r\\n\\t\\t\\tIndustry: IT-Software /  Software Services\\r\\n\\t\\t\\tFunctional Area: IT Software - Application Programming,  Maintenance\\r\\n\\t\\t\\tRole Category: Programming\\n&\\nDesign\\r\\n\\t\\t\\tRole: Database Architect/Designer\\r\\n\\t\\t\\tEmployment Type: Permanent Job, Full Time\\r\\n\\t\\t\\tKeyskills:             rhadoopsashivecluster analysisstatistical modelinganalyticsSPSS'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_description = job_soup.find(\"div\",{\"class\":\"f14 lh18 alignJ disc-li\"}).getText().strip()\n",
    "job_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# description labels (other informations about the job)\n",
    "labels = ['Salary', 'Industry', 'Functional_Area', 'Role_Category', 'Design_Role']\n",
    "#for x in job_soup.find(\"div\",{\"class\":\"jDisc mt20\"}).contents:\n",
    "#    if len(str(x).replace(' ',''))!=0 :\n",
    "#        print(x.getText().split(':')[-1].strip())\n",
    "other_info = [x.getText().split(':')[-1].strip() for x in job_soup.find(\"div\",{\"class\":\"f14 lh18 alignJ disc-li\"}).contents if len(str(x).replace(' ',''))!=0]\n",
    "other_info_label = {labels: other_info for labels, other_info in zip(labels, other_info)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# description labels (other informations about the job)\n",
    "labels = ['Salary', 'Industry', 'Functional_Area', 'Role_Category', 'Design_Role']\n",
    "#for x in job_soup.find(\"div\",{\"class\":\"jDisc mt20\"}).contents:\n",
    "#    if len(str(x).replace(' ',''))!=0 :\n",
    "#        print(x.getText().split(':')[-1].strip())\n",
    "other_info = [x.getText().split(':')[-1].strip() for x in job_soup.find(\"div\",{\"class\":\"f14 lh18 alignJ disc-li\"}).contents if \"Salary\" in x]\n",
    "other_info_label = {labels: other_info for labels, other_info in zip(labels, other_info)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<br>\\n<br>\\r\\n\\t\\t\\tSalary', '                Not Disclosed by Recruiter<br>\\r\\n\\t\\t\\tIndustry', ' <a href=\"https', '//www.naukri.com/it-software-jobs\" title=\"Find all jobs matching IT Software\"><span>IT-Software </span></a>/ <a href=\"https', '//www.naukri.com/software-services-jobs\" title=\"Find all jobs matching Software Services\"><span> Software Services</span></a><br/>\\r\\n\\t\\t\\tFunctional Area', ' <a href=\"https', '//www.naukri.com/it-software-application-programming-jobs\" title=\"Find all jobs matching IT Software Application Programming\"><span>IT Software - Application Programming</span></a>, <a href=\"https', '//www.naukri.com/maintenance-jobs\" title=\"Find all jobs matching Maintenance\"><span> Maintenance</span></a><br/>\\r\\n\\t\\t\\tRole Category', ' Programming\\n&amp;\\nDesign<br/>\\r\\n\\t\\t\\tRole', ' Database Architect/Designer<br/>\\r\\n\\t\\t\\tEmployment Type', ' Permanent Job, Full Time<br/>\\r\\n\\t\\t\\tKeyskills', '             <div class=\"cl\"><a class=\"tag\" href=\"/r-jobs\" title=\"Find all jobs matching r\"><span>r</span></a><a class=\"tag\" href=\"/hadoop-jobs\" title=\"Find all jobs matching hadoop\"><span>hadoop</span></a><a class=\"tag\" href=\"/sas-jobs\" title=\"Find all jobs matching sas\"><span>sas</span></a><a class=\"tag\" href=\"/hive-jobs\" title=\"Find all jobs matching hive\"><span>hive</span></a><a class=\"tag\" href=\"/cluster-analysis-jobs\" title=\"Find all jobs matching cluster analysis\"><span>cluster analysis</span></a><a class=\"tag\" href=\"/statistical-modeling-jobs\" title=\"Find all jobs matching statistical modeling\"><span>statistical modeling</span></a><a class=\"tag\" href=\"/analytics-jobs\" title=\"Find all jobs matching analytics\"><span>analytics</span></a><a class=\"tag\" href=\"/spss-jobs\" title=\"Find all jobs matching SPSS\"><span>SPSS</span></a></div></br></br></br>']\n"
     ]
    }
   ],
   "source": [
    "for x in job_soup.find(\"div\",{\"class\":\"f14 lh18 alignJ disc-li\"}).contents:\n",
    "    if \"Keyskills\" in str(x):\n",
    "        print(str(x).split(\":\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "other_info_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'getText'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-33b40b5c6773>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;31m# two spaces for split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mkey_skills\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m','\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob_soup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"div\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"class\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m\"ksTags\"\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetText\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"  \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mkey_skills\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'getText'"
     ]
    }
   ],
   "source": [
    "# two spaces for split\n",
    "key_skills = ','.join(job_soup.find(\"div\",{\"class\":\"ksTags\"}).getText().split(\"  \"))[1:]\n",
    "key_skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'getText'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-79-a3572eb79c29>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mskill_experience\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjob_soup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ul\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"class\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m\"listing mt15\"\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetText\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mskill_experience\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'getText'"
     ]
    }
   ],
   "source": [
    "skill_experience = job_soup.find(\"ul\",{\"class\":\"listing mt15\"}).getText().strip()\n",
    "skill_experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'contents'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-80-872674e43d29>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;31m# This is inside a javascript button : BeautifulSoup is HTML parser: For this need SELENIUM\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mrec_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"Recruiter Name\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Contact Company\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Website\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Reference Id\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mrecruiter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetText\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m':'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mjob_soup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"div\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"class\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m\"jDisc\"\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontents\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m!=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mrecruiter_info\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0minfo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrecruiter\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrec_labels\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'contents'"
     ]
    }
   ],
   "source": [
    "# This is inside a javascript button : BeautifulSoup is HTML parser: For this need SELENIUM\n",
    "rec_labels = [\"Recruiter Name\", \"Contact Company\", \"Website\", \"Reference Id\"]\n",
    "recruiter = [x.getText().split(':') for x in job_soup.find(\"div\",{\"class\":\"jDisc\"}).contents if len(str(x).replace(' ',''))!=0]\n",
    "recruiter_info = {label.strip(): info.strip() for label, info in recruiter}\n",
    "for l in rec_labels:\n",
    "    if l not in recruiter_info.keys():\n",
    "        recruiter_info[l] = \"\"\n",
    "\n",
    "recruiter_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialize the data frame every time before starting the scrap job\n",
    "job_df = pd.DataFrame()\n",
    "\n",
    "# df to validate with the un-scraped links from job_df\n",
    "job_links_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 20)\n",
      "(2, 20)\n",
      "(3, 20)\n",
      "(4, 20)\n",
      "(5, 20)\n",
      "(6, 20)\n",
      "(7, 20)\n",
      "(8, 20)\n",
      "(9, 20)\n",
      "(10, 20)\n",
      "(11, 20)\n",
      "(12, 20)\n",
      "(13, 20)\n",
      "(14, 20)\n",
      "(15, 20)\n",
      "(16, 20)\n",
      "(17, 20)\n",
      "(18, 20)\n",
      "(19, 20)\n",
      "(20, 20)\n",
      "(21, 20)\n",
      "(22, 20)\n",
      "(23, 20)\n",
      "(24, 20)\n",
      "(25, 20)\n",
      "(26, 20)\n",
      "(27, 20)\n",
      "(28, 20)\n",
      "(29, 20)\n",
      "(30, 20)\n",
      "(31, 20)\n",
      "(32, 20)\n",
      "(33, 20)\n",
      "(34, 20)\n",
      "page1\n",
      "(35, 20)\n",
      "(36, 20)\n",
      "(37, 20)\n",
      "(38, 20)\n",
      "(39, 20)\n",
      "(40, 20)\n",
      "(41, 20)\n",
      "(42, 20)\n",
      "(43, 20)\n",
      "(44, 20)\n",
      "(45, 20)\n",
      "(46, 20)\n",
      "(47, 20)\n",
      "(48, 20)\n",
      "(49, 20)\n",
      "(50, 20)\n",
      "(51, 20)\n",
      "(52, 20)\n",
      "(53, 20)\n",
      "(54, 20)\n",
      "(55, 20)\n",
      "(56, 20)\n",
      "(57, 20)\n",
      "(58, 20)\n",
      "(59, 20)\n",
      "(60, 20)\n",
      "(61, 20)\n",
      "(62, 20)\n",
      "(63, 20)\n",
      "(64, 20)\n",
      "(65, 20)\n",
      "(66, 20)\n",
      "(67, 20)\n",
      "(68, 20)\n",
      "(69, 20)\n",
      "(70, 20)\n",
      "page2\n",
      "(71, 20)\n",
      "(72, 20)\n",
      "(73, 20)\n",
      "(74, 20)\n",
      "(75, 20)\n",
      "(76, 20)\n",
      "(77, 20)\n",
      "(78, 20)\n",
      "(79, 20)\n",
      "(80, 20)\n",
      "(81, 20)\n",
      "(82, 20)\n",
      "(83, 20)\n",
      "(84, 20)\n",
      "(85, 20)\n",
      "(86, 20)\n",
      "(87, 20)\n",
      "(88, 20)\n",
      "(89, 20)\n",
      "(90, 20)\n",
      "(91, 20)\n",
      "(92, 20)\n",
      "(93, 20)\n",
      "(94, 20)\n",
      "(95, 20)\n",
      "(96, 20)\n",
      "(97, 20)\n",
      "(98, 20)\n",
      "(99, 20)\n",
      "(100, 20)\n",
      "(101, 20)\n",
      "(102, 20)\n",
      "(103, 20)\n",
      "page3\n",
      "(104, 20)\n",
      "(105, 20)\n",
      "(106, 20)\n",
      "(107, 20)\n",
      "(108, 20)\n",
      "(109, 20)\n",
      "(110, 20)\n",
      "(111, 20)\n",
      "(112, 20)\n",
      "(113, 20)\n",
      "(114, 20)\n",
      "(115, 20)\n",
      "(116, 20)\n",
      "(117, 20)\n",
      "(118, 20)\n",
      "(119, 20)\n",
      "(120, 20)\n",
      "(121, 20)\n",
      "(122, 20)\n",
      "(123, 20)\n",
      "(124, 20)\n",
      "(125, 20)\n",
      "(126, 20)\n",
      "(127, 20)\n",
      "(128, 20)\n",
      "(129, 20)\n",
      "(130, 20)\n",
      "(131, 20)\n",
      "(132, 20)\n",
      "(133, 20)\n",
      "(134, 20)\n",
      "(135, 20)\n",
      "page4\n",
      "(136, 20)\n",
      "(137, 20)\n",
      "(138, 20)\n",
      "(139, 20)\n",
      "(140, 20)\n",
      "(141, 20)\n",
      "(142, 20)\n",
      "(143, 20)\n",
      "(144, 20)\n",
      "(145, 20)\n",
      "(146, 20)\n",
      "(147, 20)\n",
      "(148, 20)\n",
      "(149, 20)\n",
      "(150, 20)\n",
      "(151, 20)\n",
      "(152, 20)\n",
      "(153, 20)\n",
      "(154, 20)\n",
      "(155, 20)\n",
      "(156, 20)\n",
      "(157, 20)\n",
      "(158, 20)\n",
      "(159, 20)\n",
      "(160, 20)\n",
      "(161, 20)\n",
      "(162, 20)\n",
      "(163, 20)\n",
      "(164, 20)\n",
      "(165, 20)\n",
      "page5\n",
      "(166, 20)\n",
      "(167, 20)\n",
      "(168, 20)\n",
      "(169, 20)\n",
      "(170, 20)\n",
      "(171, 20)\n",
      "(172, 20)\n",
      "(173, 20)\n",
      "(174, 20)\n",
      "(175, 20)\n",
      "(176, 20)\n",
      "(177, 20)\n",
      "(178, 20)\n",
      "(179, 20)\n",
      "(180, 20)\n",
      "(181, 20)\n",
      "(182, 20)\n",
      "(183, 20)\n",
      "(184, 20)\n",
      "(185, 20)\n",
      "(186, 20)\n",
      "(187, 20)\n",
      "(188, 20)\n",
      "(189, 20)\n",
      "(190, 20)\n",
      "(191, 20)\n",
      "(192, 20)\n",
      "(193, 20)\n",
      "(194, 20)\n",
      "(195, 20)\n",
      "(196, 20)\n",
      "(197, 20)\n",
      "(198, 20)\n",
      "(199, 20)\n",
      "(200, 20)\n",
      "(201, 20)\n",
      "(202, 20)\n",
      "(203, 20)\n",
      "(204, 20)\n",
      "(205, 20)\n",
      "page6\n",
      "(206, 20)\n",
      "(207, 20)\n",
      "(208, 20)\n",
      "(209, 20)\n",
      "(210, 20)\n",
      "(211, 20)\n",
      "(212, 20)\n",
      "(213, 20)\n",
      "(214, 20)\n",
      "(215, 20)\n",
      "(216, 20)\n",
      "(217, 20)\n",
      "(218, 20)\n",
      "(219, 20)\n",
      "(220, 20)\n",
      "(221, 20)\n",
      "(222, 20)\n",
      "(223, 20)\n",
      "(224, 20)\n",
      "(225, 20)\n",
      "(226, 20)\n",
      "(227, 20)\n",
      "(228, 20)\n",
      "(229, 20)\n",
      "(230, 20)\n",
      "(231, 20)\n",
      "(232, 20)\n",
      "(233, 20)\n",
      "(234, 20)\n",
      "(235, 20)\n",
      "(236, 20)\n",
      "(237, 20)\n",
      "(238, 20)\n",
      "(239, 20)\n",
      "(240, 20)\n",
      "(241, 20)\n",
      "page7\n",
      "(242, 20)\n",
      "(243, 20)\n",
      "(244, 20)\n",
      "(245, 20)\n",
      "(246, 20)\n",
      "(247, 20)\n",
      "(248, 20)\n",
      "(249, 20)\n",
      "(250, 20)\n",
      "(251, 20)\n",
      "(252, 20)\n",
      "(253, 20)\n",
      "(254, 20)\n",
      "(255, 20)\n",
      "(256, 20)\n",
      "(257, 20)\n",
      "(258, 20)\n",
      "(259, 20)\n",
      "(260, 20)\n",
      "(261, 20)\n",
      "(262, 20)\n",
      "(263, 20)\n",
      "(264, 20)\n",
      "(265, 20)\n",
      "(266, 20)\n",
      "(267, 20)\n",
      "(268, 20)\n",
      "(269, 20)\n",
      "(270, 20)\n",
      "(271, 20)\n",
      "(272, 20)\n",
      "(273, 20)\n",
      "(274, 20)\n",
      "(275, 20)\n",
      "(276, 20)\n",
      "(277, 20)\n",
      "page8\n",
      "(278, 20)\n",
      "(279, 20)\n",
      "(280, 20)\n",
      "(281, 20)\n",
      "(282, 20)\n",
      "(283, 20)\n",
      "(284, 20)\n",
      "(285, 20)\n",
      "(286, 20)\n",
      "(287, 20)\n",
      "(288, 20)\n",
      "(289, 20)\n",
      "(290, 20)\n",
      "(291, 20)\n",
      "(292, 20)\n",
      "(293, 20)\n",
      "(294, 20)\n",
      "(295, 20)\n",
      "(296, 20)\n",
      "(297, 20)\n",
      "(298, 20)\n",
      "(299, 20)\n",
      "(300, 20)\n",
      "(301, 20)\n",
      "(302, 20)\n",
      "(303, 20)\n",
      "(304, 20)\n",
      "(305, 20)\n",
      "(306, 20)\n",
      "(307, 20)\n",
      "(308, 20)\n",
      "(309, 20)\n",
      "(310, 20)\n",
      "(311, 20)\n",
      "(312, 20)\n",
      "(313, 20)\n",
      "page9\n",
      "(314, 20)\n",
      "(315, 20)\n",
      "(316, 20)\n",
      "(317, 20)\n",
      "(318, 20)\n",
      "(319, 20)\n",
      "(320, 20)\n",
      "(321, 20)\n",
      "(322, 20)\n",
      "(323, 20)\n",
      "(324, 20)\n",
      "(325, 20)\n",
      "(326, 20)\n",
      "(327, 20)\n",
      "(328, 20)\n",
      "(329, 20)\n",
      "(330, 20)\n",
      "(331, 20)\n",
      "(332, 20)\n",
      "(333, 20)\n",
      "(334, 20)\n",
      "(335, 20)\n",
      "(336, 20)\n",
      "(337, 20)\n",
      "(338, 20)\n",
      "(339, 20)\n",
      "(340, 20)\n",
      "(341, 20)\n",
      "(342, 20)\n",
      "(343, 20)\n",
      "(344, 20)\n",
      "(345, 20)\n",
      "(346, 20)\n",
      "(347, 20)\n",
      "(348, 20)\n",
      "page10\n",
      "(349, 20)\n",
      "(350, 20)\n",
      "(351, 20)\n",
      "(352, 20)\n",
      "(353, 20)\n",
      "(354, 20)\n",
      "(355, 20)\n",
      "(356, 20)\n",
      "(357, 20)\n",
      "(358, 20)\n",
      "(359, 20)\n",
      "(360, 20)\n",
      "(361, 20)\n",
      "(362, 20)\n",
      "(363, 20)\n",
      "(364, 20)\n",
      "(365, 20)\n",
      "(366, 20)\n",
      "(367, 20)\n",
      "(368, 20)\n",
      "(369, 20)\n",
      "(370, 20)\n",
      "(371, 20)\n",
      "(372, 20)\n",
      "(373, 20)\n",
      "(374, 20)\n",
      "(375, 20)\n",
      "(376, 20)\n",
      "(377, 20)\n",
      "(378, 20)\n",
      "(379, 20)\n",
      "(380, 20)\n",
      "(381, 20)\n",
      "(382, 20)\n",
      "(383, 20)\n",
      "(384, 20)\n",
      "(385, 20)\n",
      "(386, 20)\n",
      "page11\n",
      "(387, 20)\n",
      "(388, 20)\n",
      "(389, 20)\n",
      "(390, 20)\n",
      "(391, 20)\n",
      "(392, 20)\n",
      "(393, 20)\n",
      "(394, 20)\n",
      "(395, 20)\n",
      "(396, 20)\n",
      "(397, 20)\n",
      "(398, 20)\n",
      "(399, 20)\n",
      "(400, 20)\n",
      "(401, 20)\n",
      "(402, 20)\n",
      "(403, 20)\n",
      "(404, 20)\n",
      "(405, 20)\n",
      "(406, 20)\n",
      "(407, 20)\n",
      "(408, 20)\n",
      "(409, 20)\n",
      "(410, 20)\n",
      "(411, 20)\n",
      "(412, 20)\n",
      "(413, 20)\n",
      "(414, 20)\n",
      "(415, 20)\n",
      "(416, 20)\n",
      "(417, 20)\n",
      "(418, 20)\n",
      "(419, 20)\n",
      "(420, 20)\n",
      "(421, 20)\n",
      "page12\n",
      "(422, 20)\n",
      "(423, 20)\n",
      "(424, 20)\n",
      "(425, 20)\n",
      "(426, 20)\n",
      "(427, 20)\n",
      "(428, 20)\n",
      "(429, 20)\n",
      "(430, 20)\n",
      "(431, 20)\n",
      "(432, 20)\n",
      "(433, 20)\n",
      "(434, 20)\n",
      "(435, 20)\n",
      "(436, 20)\n",
      "(437, 20)\n",
      "(438, 20)\n",
      "(439, 20)\n",
      "(440, 20)\n",
      "(441, 20)\n",
      "(442, 20)\n",
      "(443, 20)\n",
      "(444, 20)\n",
      "(445, 20)\n",
      "(446, 20)\n",
      "(447, 20)\n",
      "(448, 20)\n",
      "(449, 20)\n",
      "(450, 20)\n",
      "(451, 20)\n",
      "(452, 20)\n",
      "(453, 20)\n",
      "(454, 20)\n",
      "page13\n",
      "(455, 20)\n",
      "(456, 20)\n",
      "(457, 20)\n",
      "(458, 20)\n",
      "(459, 20)\n",
      "(460, 20)\n",
      "(461, 20)\n",
      "(462, 20)\n",
      "(463, 20)\n",
      "(464, 20)\n",
      "(465, 20)\n",
      "(466, 20)\n",
      "(467, 20)\n",
      "(468, 20)\n",
      "(469, 20)\n",
      "(470, 20)\n",
      "(471, 20)\n",
      "(472, 20)\n",
      "(473, 20)\n",
      "(474, 20)\n",
      "(475, 20)\n",
      "(476, 20)\n",
      "(477, 20)\n",
      "(478, 20)\n",
      "(479, 20)\n",
      "(480, 20)\n",
      "(481, 20)\n",
      "(482, 20)\n",
      "(483, 20)\n",
      "(484, 20)\n",
      "(485, 20)\n",
      "(486, 20)\n",
      "(487, 20)\n",
      "page14\n",
      "(488, 20)\n",
      "(489, 20)\n",
      "(490, 20)\n",
      "(491, 20)\n",
      "(492, 20)\n",
      "(493, 20)\n",
      "(494, 20)\n",
      "(495, 20)\n",
      "(496, 20)\n",
      "(497, 20)\n",
      "(498, 20)\n",
      "(499, 20)\n",
      "(500, 20)\n",
      "(501, 20)\n",
      "(502, 20)\n",
      "(503, 20)\n",
      "(504, 20)\n",
      "(505, 20)\n",
      "(506, 20)\n",
      "(507, 20)\n",
      "(508, 20)\n",
      "(509, 20)\n",
      "(510, 20)\n",
      "(511, 20)\n",
      "(512, 20)\n",
      "(513, 20)\n",
      "(514, 20)\n",
      "(515, 20)\n",
      "(516, 20)\n",
      "(517, 20)\n",
      "(518, 20)\n",
      "(519, 20)\n",
      "(520, 20)\n",
      "(521, 20)\n",
      "(522, 20)\n",
      "(523, 20)\n",
      "(524, 20)\n",
      "(525, 20)\n",
      "(526, 20)\n",
      "(527, 20)\n",
      "(528, 20)\n",
      "page15\n",
      "(529, 20)\n",
      "(530, 20)\n",
      "(531, 20)\n",
      "(532, 20)\n",
      "(533, 20)\n",
      "(534, 20)\n",
      "(535, 20)\n",
      "(536, 20)\n",
      "(537, 20)\n",
      "(538, 20)\n",
      "(539, 20)\n",
      "(540, 20)\n",
      "(541, 20)\n",
      "(542, 20)\n",
      "(543, 20)\n",
      "(544, 20)\n",
      "(545, 20)\n",
      "(546, 20)\n",
      "(547, 20)\n",
      "(548, 20)\n",
      "(549, 20)\n",
      "(550, 20)\n",
      "(551, 20)\n",
      "(552, 20)\n",
      "(553, 20)\n",
      "(554, 20)\n",
      "(555, 20)\n",
      "(556, 20)\n",
      "(557, 20)\n",
      "(558, 20)\n",
      "(559, 20)\n",
      "(560, 20)\n",
      "(561, 20)\n",
      "(562, 20)\n",
      "(563, 20)\n",
      "(564, 20)\n",
      "(565, 20)\n",
      "(566, 20)\n",
      "(567, 20)\n",
      "(568, 20)\n",
      "(569, 20)\n",
      "(570, 20)\n",
      "(571, 20)\n",
      "(572, 20)\n",
      "page16\n",
      "(573, 20)\n",
      "(574, 20)\n",
      "(575, 20)\n",
      "(576, 20)\n",
      "(577, 20)\n",
      "(578, 20)\n",
      "(579, 20)\n",
      "(580, 20)\n",
      "(581, 20)\n",
      "(582, 20)\n",
      "(583, 20)\n",
      "(584, 20)\n",
      "(585, 20)\n",
      "(586, 20)\n",
      "(587, 20)\n",
      "(588, 20)\n",
      "(589, 20)\n",
      "(590, 20)\n",
      "(591, 20)\n",
      "(592, 20)\n",
      "(593, 20)\n",
      "(594, 20)\n",
      "(595, 20)\n",
      "(596, 20)\n",
      "(597, 20)\n",
      "(598, 20)\n",
      "(599, 20)\n",
      "(600, 20)\n",
      "(601, 20)\n",
      "(602, 20)\n",
      "(603, 20)\n",
      "(604, 20)\n",
      "(605, 20)\n",
      "(606, 20)\n",
      "page17\n",
      "(607, 20)\n",
      "(608, 20)\n",
      "(609, 20)\n",
      "(610, 20)\n",
      "(611, 20)\n",
      "(612, 20)\n",
      "(613, 20)\n",
      "(614, 20)\n",
      "(615, 20)\n",
      "(616, 20)\n",
      "(617, 20)\n",
      "(618, 20)\n",
      "(619, 20)\n",
      "(620, 20)\n",
      "(621, 20)\n",
      "(622, 20)\n",
      "(623, 20)\n",
      "(624, 20)\n",
      "(625, 20)\n",
      "(626, 20)\n",
      "(627, 20)\n",
      "(628, 20)\n",
      "(629, 20)\n",
      "(630, 20)\n",
      "(631, 20)\n",
      "(632, 20)\n",
      "(633, 20)\n",
      "(634, 20)\n",
      "(635, 20)\n",
      "(636, 20)\n",
      "(637, 20)\n",
      "(638, 20)\n",
      "(639, 20)\n",
      "(640, 20)\n",
      "(641, 20)\n",
      "(642, 20)\n",
      "(643, 20)\n",
      "(644, 20)\n",
      "(645, 20)\n",
      "(646, 20)\n",
      "(647, 20)\n",
      "(648, 20)\n",
      "(649, 20)\n",
      "page18\n",
      "(650, 20)\n",
      "(651, 20)\n",
      "(652, 20)\n",
      "(653, 20)\n",
      "(654, 20)\n",
      "(655, 20)\n",
      "(656, 20)\n",
      "(657, 20)\n",
      "(658, 20)\n",
      "(659, 20)\n",
      "(660, 20)\n",
      "(661, 20)\n",
      "(662, 20)\n",
      "(663, 20)\n",
      "(664, 20)\n",
      "(665, 20)\n",
      "(666, 20)\n",
      "(667, 20)\n",
      "(668, 20)\n",
      "(669, 20)\n",
      "(670, 20)\n",
      "(671, 20)\n",
      "(672, 20)\n",
      "(673, 20)\n",
      "(674, 20)\n",
      "(675, 20)\n",
      "(676, 20)\n",
      "(677, 20)\n",
      "(678, 20)\n",
      "(679, 20)\n",
      "(680, 20)\n",
      "(681, 20)\n",
      "(682, 20)\n",
      "(683, 20)\n",
      "(684, 20)\n",
      "(685, 20)\n",
      "(686, 20)\n",
      "(687, 20)\n",
      "(688, 20)\n",
      "(689, 20)\n",
      "(690, 20)\n",
      "(691, 20)\n",
      "page19\n",
      "(692, 20)\n",
      "(693, 20)\n",
      "(694, 20)\n",
      "(695, 20)\n",
      "(696, 20)\n",
      "(697, 20)\n",
      "(698, 20)\n",
      "(699, 20)\n",
      "(700, 20)\n",
      "(701, 20)\n",
      "(702, 20)\n",
      "(703, 20)\n",
      "(704, 20)\n",
      "(705, 20)\n",
      "(706, 20)\n",
      "(707, 20)\n",
      "(708, 20)\n",
      "(709, 20)\n",
      "(710, 20)\n",
      "(711, 20)\n",
      "(712, 20)\n",
      "(713, 20)\n",
      "(714, 20)\n",
      "(715, 20)\n",
      "(716, 20)\n",
      "(717, 20)\n",
      "(718, 20)\n",
      "(719, 20)\n",
      "(720, 20)\n",
      "(721, 20)\n",
      "(722, 20)\n",
      "(723, 20)\n",
      "(724, 20)\n",
      "(725, 20)\n",
      "(726, 20)\n",
      "(727, 20)\n",
      "page20\n",
      "(728, 20)\n",
      "(729, 20)\n",
      "(730, 20)\n",
      "(731, 20)\n",
      "(732, 20)\n",
      "(733, 20)\n",
      "(734, 20)\n",
      "(735, 20)\n",
      "(736, 20)\n",
      "(737, 20)\n",
      "(738, 20)\n",
      "(739, 20)\n",
      "(740, 20)\n",
      "(741, 20)\n",
      "(742, 20)\n",
      "(743, 20)\n",
      "(744, 20)\n",
      "(745, 20)\n",
      "(746, 20)\n",
      "(747, 20)\n",
      "(748, 20)\n",
      "(749, 20)\n",
      "(750, 20)\n",
      "(751, 20)\n",
      "(752, 20)\n",
      "(753, 20)\n",
      "(754, 20)\n",
      "(755, 20)\n",
      "(756, 20)\n",
      "(757, 20)\n",
      "(758, 20)\n",
      "(759, 20)\n",
      "page21\n",
      "(760, 20)\n",
      "(761, 20)\n",
      "(762, 20)\n",
      "(763, 20)\n",
      "(764, 20)\n",
      "(765, 20)\n",
      "(766, 20)\n",
      "(767, 20)\n",
      "(768, 20)\n",
      "(769, 20)\n",
      "(770, 20)\n",
      "(771, 20)\n",
      "(772, 20)\n",
      "(773, 20)\n",
      "(774, 20)\n",
      "(775, 20)\n",
      "(776, 20)\n",
      "(777, 20)\n",
      "(778, 20)\n",
      "(779, 20)\n",
      "(780, 20)\n",
      "(781, 20)\n",
      "(782, 20)\n",
      "(783, 20)\n",
      "(784, 20)\n",
      "(785, 20)\n",
      "(786, 20)\n",
      "(787, 20)\n",
      "(788, 20)\n",
      "(789, 20)\n",
      "(790, 20)\n",
      "(791, 20)\n",
      "(792, 20)\n",
      "page22\n",
      "(793, 20)\n",
      "(794, 20)\n",
      "(795, 20)\n",
      "(796, 20)\n",
      "(797, 20)\n",
      "(798, 20)\n",
      "(799, 20)\n",
      "(800, 20)\n",
      "(801, 20)\n",
      "(802, 20)\n",
      "(803, 20)\n",
      "(804, 20)\n",
      "(805, 20)\n",
      "(806, 20)\n",
      "(807, 20)\n",
      "(808, 20)\n",
      "(809, 20)\n",
      "(810, 20)\n",
      "(811, 20)\n",
      "(812, 20)\n",
      "(813, 20)\n",
      "(814, 20)\n",
      "(815, 20)\n",
      "(816, 20)\n",
      "page23\n",
      "(817, 20)\n",
      "(818, 20)\n",
      "(819, 20)\n",
      "(820, 20)\n",
      "(821, 20)\n",
      "(822, 20)\n",
      "(823, 20)\n",
      "(824, 20)\n",
      "(825, 20)\n",
      "(826, 20)\n",
      "(827, 20)\n",
      "(828, 20)\n",
      "(829, 20)\n",
      "(830, 20)\n",
      "(831, 20)\n",
      "(832, 20)\n",
      "(833, 20)\n",
      "(834, 20)\n",
      "(835, 20)\n",
      "(836, 20)\n",
      "(837, 20)\n",
      "(838, 20)\n",
      "page24\n",
      "(839, 20)\n",
      "(840, 20)\n",
      "(841, 20)\n",
      "(842, 20)\n",
      "(843, 20)\n",
      "(844, 20)\n",
      "(845, 20)\n",
      "(846, 20)\n",
      "(847, 20)\n",
      "(848, 20)\n",
      "(849, 20)\n",
      "(850, 20)\n",
      "(851, 20)\n",
      "(852, 20)\n",
      "(853, 20)\n",
      "page25\n",
      "(854, 20)\n",
      "(855, 20)\n",
      "(856, 20)\n",
      "(857, 20)\n",
      "(858, 20)\n",
      "(859, 20)\n",
      "(860, 20)\n",
      "(861, 20)\n",
      "(862, 20)\n",
      "(863, 20)\n",
      "(864, 20)\n",
      "(865, 20)\n",
      "(866, 20)\n",
      "(867, 20)\n",
      "(868, 20)\n",
      "(869, 20)\n",
      "(870, 20)\n",
      "(871, 20)\n",
      "(872, 20)\n",
      "(873, 20)\n",
      "(874, 20)\n",
      "(875, 20)\n",
      "(876, 20)\n",
      "page26\n",
      "(877, 20)\n",
      "(878, 20)\n",
      "(879, 20)\n",
      "(880, 20)\n",
      "(881, 20)\n",
      "(882, 20)\n",
      "(883, 20)\n",
      "(884, 20)\n",
      "(885, 20)\n",
      "(886, 20)\n",
      "(887, 20)\n",
      "(888, 20)\n",
      "(889, 20)\n",
      "(890, 20)\n",
      "(891, 20)\n",
      "(892, 20)\n",
      "(893, 20)\n",
      "(894, 20)\n",
      "(895, 20)\n",
      "(896, 20)\n",
      "(897, 20)\n",
      "(898, 20)\n",
      "(899, 20)\n",
      "(900, 20)\n",
      "page27\n",
      "(901, 20)\n",
      "(902, 20)\n",
      "(903, 20)\n",
      "(904, 20)\n",
      "(905, 20)\n",
      "(906, 20)\n",
      "(907, 20)\n",
      "(908, 20)\n",
      "(909, 20)\n",
      "page28\n",
      "(910, 20)\n",
      "(911, 20)\n",
      "(912, 20)\n",
      "(913, 20)\n",
      "(914, 20)\n",
      "(915, 20)\n",
      "(916, 20)\n",
      "(917, 20)\n",
      "(918, 20)\n",
      "page29\n",
      "(919, 20)\n",
      "(920, 20)\n",
      "(921, 20)\n",
      "(922, 20)\n",
      "(923, 20)\n",
      "(924, 20)\n",
      "(925, 20)\n",
      "(926, 20)\n",
      "(927, 20)\n",
      "(928, 20)\n",
      "(929, 20)\n",
      "(930, 20)\n",
      "(931, 20)\n",
      "(932, 20)\n",
      "(933, 20)\n",
      "(934, 20)\n",
      "page30\n",
      "(935, 20)\n",
      "(936, 20)\n",
      "(937, 20)\n",
      "(938, 20)\n",
      "(939, 20)\n",
      "(940, 20)\n",
      "(941, 20)\n",
      "page31\n",
      "(942, 20)\n",
      "(943, 20)\n",
      "(944, 20)\n",
      "(945, 20)\n",
      "(946, 20)\n",
      "(947, 20)\n",
      "(948, 20)\n",
      "(949, 20)\n",
      "(950, 20)\n",
      "(951, 20)\n",
      "(952, 20)\n",
      "page32\n",
      "(953, 20)\n",
      "(954, 20)\n",
      "(955, 20)\n",
      "(956, 20)\n",
      "(957, 20)\n",
      "(958, 20)\n",
      "(959, 20)\n",
      "(960, 20)\n",
      "(961, 20)\n",
      "page33\n",
      "(962, 20)\n",
      "(963, 20)\n",
      "(964, 20)\n",
      "(965, 20)\n",
      "page34\n",
      "(966, 20)\n",
      "(967, 20)\n",
      "(968, 20)\n",
      "(969, 20)\n",
      "(970, 20)\n",
      "(971, 20)\n",
      "(972, 20)\n",
      "(973, 20)\n",
      "page35\n",
      "(974, 20)\n",
      "(975, 20)\n",
      "(976, 20)\n",
      "(977, 20)\n",
      "(978, 20)\n",
      "(979, 20)\n",
      "(980, 20)\n",
      "(981, 20)\n",
      "(982, 20)\n",
      "(983, 20)\n",
      "(984, 20)\n",
      "(985, 20)\n",
      "(986, 20)\n",
      "page36\n",
      "(987, 20)\n",
      "(988, 20)\n",
      "(989, 20)\n",
      "(990, 20)\n",
      "(991, 20)\n",
      "(992, 20)\n",
      "(993, 20)\n",
      "(994, 20)\n",
      "(995, 20)\n",
      "(996, 20)\n",
      "(997, 20)\n",
      "(998, 20)\n",
      "(999, 20)\n",
      "page37\n",
      "(1000, 20)\n",
      "(1001, 20)\n",
      "(1002, 20)\n",
      "(1003, 20)\n",
      "(1004, 20)\n",
      "(1005, 20)\n",
      "page38\n",
      "(1006, 20)\n",
      "(1007, 20)\n",
      "(1008, 20)\n",
      "(1009, 20)\n",
      "(1010, 20)\n",
      "(1011, 20)\n",
      "(1012, 20)\n",
      "(1013, 20)\n",
      "(1014, 20)\n",
      "page39\n",
      "(1015, 20)\n",
      "(1016, 20)\n",
      "(1017, 20)\n",
      "(1018, 20)\n",
      "(1019, 20)\n",
      "page40\n",
      "(1020, 20)\n",
      "(1021, 20)\n",
      "(1022, 20)\n",
      "(1023, 20)\n",
      "(1024, 20)\n",
      "(1025, 20)\n",
      "(1026, 20)\n",
      "(1027, 20)\n",
      "page41\n",
      "(1028, 20)\n",
      "(1029, 20)\n",
      "(1030, 20)\n",
      "(1031, 20)\n",
      "(1032, 20)\n",
      "(1033, 20)\n",
      "(1034, 20)\n",
      "page42\n",
      "(1035, 20)\n",
      "(1036, 20)\n",
      "(1037, 20)\n",
      "(1038, 20)\n",
      "(1039, 20)\n",
      "(1040, 20)\n",
      "(1041, 20)\n",
      "(1042, 20)\n",
      "(1043, 20)\n",
      "(1044, 20)\n",
      "(1045, 20)\n",
      "(1046, 20)\n",
      "(1047, 20)\n",
      "(1048, 20)\n",
      "(1049, 20)\n",
      "(1050, 20)\n",
      "(1051, 20)\n",
      "page43\n",
      "(1052, 20)\n",
      "(1053, 20)\n",
      "(1054, 20)\n",
      "(1055, 20)\n",
      "(1056, 20)\n",
      "(1057, 20)\n",
      "(1058, 20)\n",
      "(1059, 20)\n",
      "(1060, 20)\n",
      "(1061, 20)\n",
      "page44\n",
      "(1062, 20)\n",
      "(1063, 20)\n",
      "(1064, 20)\n",
      "(1065, 20)\n",
      "(1066, 20)\n",
      "(1067, 20)\n",
      "(1068, 20)\n",
      "(1069, 20)\n",
      "(1070, 20)\n",
      "(1071, 20)\n",
      "(1072, 20)\n",
      "(1073, 20)\n",
      "(1074, 20)\n",
      "(1075, 20)\n",
      "(1076, 20)\n",
      "(1077, 20)\n",
      "page45\n",
      "(1078, 20)\n",
      "(1079, 20)\n",
      "(1080, 20)\n",
      "(1081, 20)\n",
      "(1082, 20)\n",
      "(1083, 20)\n",
      "(1084, 20)\n",
      "page46\n",
      "(1085, 20)\n",
      "(1086, 20)\n",
      "(1087, 20)\n",
      "(1088, 20)\n",
      "(1089, 20)\n",
      "(1090, 20)\n",
      "(1091, 20)\n",
      "(1092, 20)\n",
      "(1093, 20)\n",
      "(1094, 20)\n",
      "page47\n",
      "(1095, 20)\n",
      "(1096, 20)\n",
      "(1097, 20)\n",
      "(1098, 20)\n",
      "(1099, 20)\n",
      "(1100, 20)\n",
      "(1101, 20)\n",
      "(1102, 20)\n",
      "(1103, 20)\n",
      "page48\n",
      "(1104, 20)\n",
      "page49\n",
      "(1105, 20)\n",
      "(1106, 20)\n",
      "(1107, 20)\n",
      "(1108, 20)\n",
      "(1109, 20)\n",
      "page50\n",
      "(1110, 20)\n",
      "(1111, 20)\n",
      "(1112, 20)\n",
      "page51\n",
      "(1113, 20)\n",
      "(1114, 20)\n",
      "(1115, 20)\n",
      "(1116, 20)\n",
      "(1117, 20)\n",
      "(1118, 20)\n",
      "(1119, 20)\n",
      "page52\n",
      "(1120, 20)\n",
      "(1121, 20)\n",
      "(1122, 20)\n",
      "(1123, 20)\n",
      "(1124, 20)\n",
      "(1125, 20)\n",
      "page53\n",
      "(1126, 20)\n",
      "(1127, 20)\n",
      "(1128, 20)\n",
      "(1129, 20)\n",
      "(1130, 20)\n",
      "(1131, 20)\n",
      "(1132, 20)\n",
      "(1133, 20)\n",
      "(1134, 20)\n",
      "(1135, 20)\n",
      "(1136, 20)\n",
      "(1137, 20)\n",
      "(1138, 20)\n",
      "(1139, 20)\n",
      "page54\n",
      "(1140, 20)\n",
      "(1141, 20)\n",
      "(1142, 20)\n",
      "(1143, 20)\n",
      "(1144, 20)\n",
      "(1145, 20)\n",
      "(1146, 20)\n",
      "(1147, 20)\n",
      "(1148, 20)\n",
      "(1149, 20)\n",
      "(1150, 20)\n",
      "(1151, 20)\n",
      "(1152, 20)\n",
      "(1153, 20)\n",
      "(1154, 20)\n",
      "(1155, 20)\n",
      "(1156, 20)\n",
      "page55\n",
      "(1157, 20)\n",
      "(1158, 20)\n",
      "(1159, 20)\n",
      "(1160, 20)\n",
      "(1161, 20)\n",
      "(1162, 20)\n",
      "(1163, 20)\n",
      "(1164, 20)\n",
      "page56\n",
      "(1165, 20)\n",
      "(1166, 20)\n",
      "(1167, 20)\n",
      "(1168, 20)\n",
      "(1169, 20)\n",
      "(1170, 20)\n",
      "(1171, 20)\n",
      "page57\n",
      "(1172, 20)\n",
      "(1173, 20)\n",
      "(1174, 20)\n",
      "(1175, 20)\n",
      "(1176, 20)\n",
      "(1177, 20)\n",
      "(1178, 20)\n",
      "(1179, 20)\n",
      "page58\n",
      "(1180, 20)\n",
      "(1181, 20)\n",
      "(1182, 20)\n",
      "(1183, 20)\n",
      "(1184, 20)\n",
      "(1185, 20)\n",
      "(1186, 20)\n",
      "(1187, 20)\n",
      "(1188, 20)\n",
      "(1189, 20)\n",
      "page59\n",
      "(1190, 20)\n",
      "(1191, 20)\n",
      "(1192, 20)\n",
      "(1193, 20)\n",
      "(1194, 20)\n",
      "(1195, 20)\n",
      "(1196, 20)\n",
      "(1197, 20)\n",
      "(1198, 20)\n",
      "(1199, 20)\n",
      "(1200, 20)\n",
      "(1201, 20)\n",
      "(1202, 20)\n",
      "(1203, 20)\n",
      "(1204, 20)\n",
      "(1205, 20)\n",
      "(1206, 20)\n",
      "(1207, 20)\n",
      "(1208, 20)\n",
      "(1209, 20)\n",
      "(1210, 20)\n",
      "(1211, 20)\n",
      "(1212, 20)\n",
      "(1213, 20)\n",
      "(1214, 20)\n",
      "(1215, 20)\n",
      "(1216, 20)\n",
      "page60\n"
     ]
    }
   ],
   "source": [
    "# Motive is to get all the data science jobs from \"https://www.naukri.com\"\n",
    "\n",
    "# URLS : \"-\" is added to help later while structuring the other pages URL\n",
    "data_scientist = \"https://www.naukri.com/data-scientist-jobs-\"\n",
    "machine_learning = \"https://www.naukri.com/machine-learning-jobs-\"\n",
    "data_analyst = \"https://www.naukri.com/data-analyst-jobs-\"\n",
    "# go till page 60\n",
    "business_analyst = \"https://www.naukri.com/business-analyst-jobs-\"\n",
    "\n",
    "# Base URL (You can write a for loop to iterate through the above URLs, I am putting it manually so that server doesn't receive lots \n",
    "# of hits at a time)\n",
    "base_url = business_analyst\n",
    "base_response = requests.get(base_url)\n",
    "base_page = base_response.text\n",
    "\n",
    "# Convert the response to BeautifulSoup object\n",
    "base_soup = BeautifulSoup(base_page, \"html.parser\")\n",
    "\n",
    "# Find the total number of jobs : which is 10043\n",
    "num_jobs = int(base_soup.find(\"div\", { \"class\" : \"count\" }).h1.contents[1].getText().split(' ')[-1])\n",
    "# Each page lists 50 jobs, so total pages\n",
    "num_pages = int(math.ceil(num_jobs/50.0))\n",
    "\n",
    "# Get all the job links, each page have 50 job links\n",
    "# pattern in page url is - https://www.naukri.com/data-scientist-jobs-page_number\n",
    "\n",
    "# Create a empty list to store all job links\n",
    "job_links = []\n",
    "\n",
    "# Want to scrap in a gap, so that I don't overload there server :: 30 for others, 60 for business_analyst, 40 for data_scientist\n",
    "req_page = 60\n",
    "# keep changing the start_ind\n",
    "start_ind = 1\n",
    "end_ind = start_ind + req_page\n",
    "\n",
    "# description labels (other informations about the job)\n",
    "labels = ['Salary', 'Industry', 'Functional_Area', 'Role_Category', 'Design_Role']\n",
    "# education requirements\n",
    "edu_labels = [\"UG\", \"PG\", \"Doctorate\"]\n",
    "# For loop to get link from each of num_pages\n",
    "# To run in a single loop USE : range(1, num_pages+1)\n",
    "for page in range(start_ind, end_ind):\n",
    "    # structuring the page URL\n",
    "    page_url = base_url + str(page)\n",
    "    page_response = requests.get(page_url)\n",
    "    page_txt = page_response.text\n",
    "    page_soup = BeautifulSoup(page_txt, \"html.parser\")\n",
    "    # 50 job links are in the class content, so filtering only content class\n",
    "    links = [l.get(\"href\") for l in page_soup.find_all(\"a\", {\"class\":\"content\"})]\n",
    "    # Append the links into job_links\n",
    "    #for pl in links:\n",
    "        #job_links.append(pl)\n",
    "    for job_url in links:\n",
    "        job_response = requests.get(job_url)\n",
    "        job_page = job_response.text\n",
    "        job_soup = BeautifulSoup(job_page, \"html.parser\")\n",
    "        # get one dataframe with all the links and response so that we can later check from which link we are not able to get data\n",
    "        jdf = OrderedDict({\"Job_Link\":job_url, \"Response\":str(job_response)})\n",
    "        job_links_df = job_links_df.append(jdf,ignore_index=True)\n",
    "        try:\n",
    "            job_title = job_soup.find(\"h1\", {\"itemprop\":\"title\"}).getText().strip()\n",
    "            company_name = job_soup.find(\"a\",{\"itemprop\":\"hiringOrganization\"}).getText().strip()\n",
    "            experience = job_soup.find(\"span\",{\"itemprop\":\"experienceRequirements\"}).getText().strip()\n",
    "            location = job_soup.find(\"div\",{\"class\":\"loc\"}).getText().strip()\n",
    "            salary = job_soup.find(\"span\",{\"class\":\"sal\"}).getText().strip()\n",
    "            #openings = job_soup.find(\"div\",{\"class\":\"sumFoot\"}).find_all(\"span\")\n",
    "            #openings\n",
    "            num_openings = \"\"\n",
    "            job_post = \"\"\n",
    "            for x in job_soup.find(\"div\",{\"class\":\"sumFoot\"}).find_all(\"span\"):\n",
    "                if \"Openings\" in x.text.strip():\n",
    "                    num_openings = x.text.strip()\n",
    "                if \"Posted\" in x.text.strip():\n",
    "                    job_post = x.text.strip()\n",
    "            job_application = job_soup.find(\"span\",{\"class\":\"jApplys\"}).find(\"strong\").getText().strip()\n",
    "            job_view = job_soup.find(\"span\",{\"class\":\"jViews\"}).find(\"strong\").getText().strip()\n",
    "            job_description = job_soup.find(\"ul\",{\"itemprop\":\"description\"}).getText().strip()\n",
    "            # description labels (other informations about the job)\n",
    "            #for x in job_soup.find(\"div\",{\"class\":\"jDisc mt20\"}).contents:\n",
    "            #    if len(str(x).replace(' ',''))!=0 :\n",
    "            #        print(x.getText().split(':')[-1].strip())\n",
    "            other_info = [x.getText().split(':')[-1].strip() for x in job_soup.find(\"div\",{\"class\":\"jDisc mt20\"}).contents if len(str(x).replace(' ',''))!=0]\n",
    "            other_info_label = {labels: other_info for labels, other_info in zip(labels, other_info)}\n",
    "            key_skills = ','.join(job_soup.find(\"div\",{\"class\":\"ksTags\"}).getText().split(\"  \"))[1:]\n",
    "            skill_experience = job_soup.find(\"ul\",{\"class\":\"listing mt15\"}).getText().strip()\n",
    "            # putting the education information\n",
    "            education = [x.getText().split(':') for x in job_soup.find(\"div\",{\"itemprop\":\"educationRequirements\"}).contents if len(str(x).replace(' ',''))!=0]\n",
    "            education_info = {edu_label.strip(): education.strip() for edu_label, education in education}\n",
    "            for l in edu_labels:\n",
    "                if l not in education_info.keys():\n",
    "                    education_info[l] = \"\"\n",
    "            # recruiter information\n",
    "            # This is inside a javascript button : BeautifulSoup is HTML parser: For this need SELENIUM\n",
    "        except AttributeError:\n",
    "            continue\n",
    "        df = OrderedDict({'Job_Link':job_url, 'Job_Title':job_title, 'Company_Name':company_name, 'Experience':experience, 'Location':location, 'SalaryI':salary, 'Num_Openings':num_openings,\n",
    "                          'Job_Post':job_post, 'Job_Application':job_application,\n",
    "                          'Job_View':job_view, 'Key_Skills':key_skills, 'Skill_Experience':skill_experience})\n",
    "        df.update(other_info_label)\n",
    "        df.update(education_info)\n",
    "        job_df = job_df.append(df,ignore_index=True)\n",
    "        print(job_df.shape)\n",
    "        time.sleep(1)\n",
    "    print(\"page\" + str(page))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Going to Query Job by different KeyWords Like Data Scientist, Data Analyst, Business Analyst, Machine Learning etc.\n",
    "# Though there is many pages for each key-word, after 20-25 pages I am noticing that Jobs are not as data scientist or the keyword, they matched because of the some portion of\n",
    "# key word like (data-scientist-analyst-business-machine-learning) mathced.\n",
    "# So for various keywords, instead of getting all the pages data, I will simply get first 20-30 page of data\n",
    "# Here is one concern that job can repeat in searches, so need to remove the duplicate based on job_url, company_name, job_titel etc\n",
    "\n",
    "# Again there are many links which we were not able to execute, we will filter out those links and run the scrap job again based on the un-executed links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_links_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Saving the data in pkl format\n",
    "import _pickle as cPickle\n",
    "# Python 3, _pickle\n",
    "column_names = ['Job_Link', 'Job_Title', 'Company_Name', 'Experience', 'Location', 'SalaryI', 'Num_Openings', 'Job_Post', 'Job_Application',\n",
    "                'Job_View', 'Salary', 'Industry', 'Functional_Area', 'Role_Category', 'Design_Role', 'Key_Skills', 'Skill_Experience', \"UG\",\n",
    "                \"PG\", \"Doctorate\"]\n",
    "\n",
    "job_df= job_df.reindex(columns=column_names)        \n",
    "with open('job_df_business_analyst.pkl', 'wb') as f:\n",
    "    cPickle.dump(job_df, f)\n",
    "\n",
    "# Save the scraped links\n",
    "with open(\"job_links_df_business_analyst.pkl\", \"wb\") as f:\n",
    "    cPickle.dump(job_links_df, f)\n",
    "\n",
    "# Read canned scraped links\n",
    "# Some error here ?\n",
    "#with open('job_df.pkl', 'r') as f:\n",
    "#    job_df = cPickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save as csv\n",
    "job_df.to_csv(\"job_df_business_analyst.csv\", encoding='utf8')\n",
    "job_links_df.to_csv(\"job_links_df_business_analyst.csv\", encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "apnd_dfs20 = pd.DataFrame()\n",
    "apnd_dfs20 = apnd_dfs20.append(job_df, ignore_index = True)\n",
    "apnd_dfs20.reindex(columns=column_names)\n",
    "\n",
    "ap_jb_ln = pd.DataFrame()\n",
    "ap_jb_ln = ap_jb_ln.append(job_links_df, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_Link</th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Location</th>\n",
       "      <th>SalaryI</th>\n",
       "      <th>Num_Openings</th>\n",
       "      <th>Job_Post</th>\n",
       "      <th>Job_Application</th>\n",
       "      <th>Job_View</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Industry</th>\n",
       "      <th>Functional_Area</th>\n",
       "      <th>Role_Category</th>\n",
       "      <th>Design_Role</th>\n",
       "      <th>Key_Skills</th>\n",
       "      <th>Skill_Experience</th>\n",
       "      <th>UG</th>\n",
       "      <th>PG</th>\n",
       "      <th>Doctorate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.naukri.com/job-listings-Accounts-F...</td>\n",
       "      <td>Accounts &amp; Finance Executive</td>\n",
       "      <td>VASK InfoEdge Pvt. Ltd.</td>\n",
       "      <td>3 - 6 yrs</td>\n",
       "      <td>Bhopal</td>\n",
       "      <td>Not Disclosed by Recruiter</td>\n",
       "      <td>Openings: 1</td>\n",
       "      <td>Posted 1 day ago</td>\n",
       "      <td>15</td>\n",
       "      <td>107</td>\n",
       "      <td>Not Disclosed by Recruiter</td>\n",
       "      <td>IT-Software  /    Software Services</td>\n",
       "      <td>Accounts   ,     Finance   ,     Tax   ,     C...</td>\n",
       "      <td>Accounts</td>\n",
       "      <td>Accounts Executive/Accountant</td>\n",
       "      <td>accounting,finance,banking,deposits,Hindi Typi...</td>\n",
       "      <td>. Monitoring data management to keep accurate ...</td>\n",
       "      <td>Any Graduate - Any Specialization</td>\n",
       "      <td>Any Postgraduate - Any Specialization</td>\n",
       "      <td>Doctorate Not Required</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.naukri.com/job-listings-Godrej-Sec...</td>\n",
       "      <td>Godrej Security Solutions - Sr. Exec / Asst. M...</td>\n",
       "      <td>Godrej and Boyce Mfg. Co. Ltd</td>\n",
       "      <td>2 - 7 yrs</td>\n",
       "      <td>Jaipur</td>\n",
       "      <td>Not Disclosed by Recruiter</td>\n",
       "      <td></td>\n",
       "      <td>Posted 1 day ago</td>\n",
       "      <td>104</td>\n",
       "      <td>155</td>\n",
       "      <td>Not Disclosed by Recruiter</td>\n",
       "      <td>Consumer Electronics  /    Appliances  /    Du...</td>\n",
       "      <td>Sales   ,     Retail   ,     Business Development</td>\n",
       "      <td>Channel Sales</td>\n",
       "      <td>Sales Executive / Officer</td>\n",
       "      <td>B2C Sales,Dealer Management,Channel Sales,Dist...</td>\n",
       "      <td>Please refer to the Job description above</td>\n",
       "      <td>B.Tech/B.E. - Any Specialization, B.Sc - Any S...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.naukri.com/job-listings-Formulatio...</td>\n",
       "      <td>Formulation &amp; Development - Executive</td>\n",
       "      <td>Naprod Life Sciences Private Limited</td>\n",
       "      <td>5 - 7 yrs</td>\n",
       "      <td>Tarapur</td>\n",
       "      <td>2,50,000 - 3,00,000 P.A.</td>\n",
       "      <td>Openings: 1</td>\n",
       "      <td>Posted 15 days ago</td>\n",
       "      <td>38</td>\n",
       "      <td>466</td>\n",
       "      <td>INR  2,50,000 - 3,00,000 P.A.</td>\n",
       "      <td>Pharma  /    Biotech  /    Clinical Research</td>\n",
       "      <td>Production   ,     Manufacturing   ,     Maint...</td>\n",
       "      <td>Production/Manufacturing/Maintenance</td>\n",
       "      <td>Quality Assurance/Quality Control Executive</td>\n",
       "      <td>Formulation Development,SVP,injectable,oncolog...</td>\n",
       "      <td>We are looking for a Male candidate with minim...</td>\n",
       "      <td>B.Pharma - Pharmacy</td>\n",
       "      <td>M.Pharma - Pharmacy</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.naukri.com/job-listings-Formulatio...</td>\n",
       "      <td>Formulation &amp; Development - Officer</td>\n",
       "      <td>Naprod Life Sciences Private Limited</td>\n",
       "      <td>1 - 2 yrs</td>\n",
       "      <td>Tarapur</td>\n",
       "      <td>1,00,000 - 2,00,000 P.A.</td>\n",
       "      <td>Openings: 1</td>\n",
       "      <td>Posted 15 days ago</td>\n",
       "      <td>141</td>\n",
       "      <td>723</td>\n",
       "      <td>INR  1,00,000 - 2,00,000 P.A.</td>\n",
       "      <td>Pharma  /    Biotech  /    Clinical Research</td>\n",
       "      <td>Production   ,     Manufacturing   ,     Maint...</td>\n",
       "      <td>Production/Manufacturing/Maintenance</td>\n",
       "      <td>Quality Assurance/Quality Control Executive</td>\n",
       "      <td>Formulation Development,SVP,injectable,oncolog...</td>\n",
       "      <td>We are looking for a Male candidate with minim...</td>\n",
       "      <td>B.Pharma - Pharmacy</td>\n",
       "      <td>M.Pharma - Pharmacy</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.naukri.com/job-listings-MIS-Execut...</td>\n",
       "      <td>MIS Executive</td>\n",
       "      <td>Marion Biotech Private Limited</td>\n",
       "      <td>1 - 3 yrs</td>\n",
       "      <td>Noida</td>\n",
       "      <td>2,00,000 - 3,00,000 P.A.</td>\n",
       "      <td></td>\n",
       "      <td>Posted 1 day ago</td>\n",
       "      <td>2000+</td>\n",
       "      <td>5000+</td>\n",
       "      <td>INR  2,00,000 - 3,00,000 P.A.</td>\n",
       "      <td>Pharma  /    Biotech  /    Clinical Research</td>\n",
       "      <td>Executive Assistant   ,     Front Office   ,  ...</td>\n",
       "      <td>Other</td>\n",
       "      <td>Stenographer/Data Entry Operator</td>\n",
       "      <td>Primary Sales,MIS Preparation,Management infor...</td>\n",
       "      <td>*Any Graduate or Post Graduate with previous w...</td>\n",
       "      <td>Any Graduate - Any Specialization</td>\n",
       "      <td>Post Graduation Not Required</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Job_Link  \\\n",
       "0  https://www.naukri.com/job-listings-Accounts-F...   \n",
       "1  https://www.naukri.com/job-listings-Godrej-Sec...   \n",
       "2  https://www.naukri.com/job-listings-Formulatio...   \n",
       "3  https://www.naukri.com/job-listings-Formulatio...   \n",
       "4  https://www.naukri.com/job-listings-MIS-Execut...   \n",
       "\n",
       "                                           Job_Title  \\\n",
       "0                       Accounts & Finance Executive   \n",
       "1  Godrej Security Solutions - Sr. Exec / Asst. M...   \n",
       "2              Formulation & Development - Executive   \n",
       "3                Formulation & Development - Officer   \n",
       "4                                      MIS Executive   \n",
       "\n",
       "                           Company_Name Experience Location  \\\n",
       "0               VASK InfoEdge Pvt. Ltd.  3 - 6 yrs   Bhopal   \n",
       "1         Godrej and Boyce Mfg. Co. Ltd  2 - 7 yrs   Jaipur   \n",
       "2  Naprod Life Sciences Private Limited  5 - 7 yrs  Tarapur   \n",
       "3  Naprod Life Sciences Private Limited  1 - 2 yrs  Tarapur   \n",
       "4        Marion Biotech Private Limited  1 - 3 yrs    Noida   \n",
       "\n",
       "                      SalaryI Num_Openings            Job_Post  \\\n",
       "0  Not Disclosed by Recruiter  Openings: 1    Posted 1 day ago   \n",
       "1  Not Disclosed by Recruiter                 Posted 1 day ago   \n",
       "2    2,50,000 - 3,00,000 P.A.  Openings: 1  Posted 15 days ago   \n",
       "3    1,00,000 - 2,00,000 P.A.  Openings: 1  Posted 15 days ago   \n",
       "4    2,00,000 - 3,00,000 P.A.                 Posted 1 day ago   \n",
       "\n",
       "  Job_Application Job_View                         Salary  \\\n",
       "0              15      107     Not Disclosed by Recruiter   \n",
       "1             104      155     Not Disclosed by Recruiter   \n",
       "2              38      466  INR  2,50,000 - 3,00,000 P.A.   \n",
       "3             141      723  INR  1,00,000 - 2,00,000 P.A.   \n",
       "4           2000+    5000+  INR  2,00,000 - 3,00,000 P.A.   \n",
       "\n",
       "                                            Industry  \\\n",
       "0                IT-Software  /    Software Services   \n",
       "1  Consumer Electronics  /    Appliances  /    Du...   \n",
       "2       Pharma  /    Biotech  /    Clinical Research   \n",
       "3       Pharma  /    Biotech  /    Clinical Research   \n",
       "4       Pharma  /    Biotech  /    Clinical Research   \n",
       "\n",
       "                                     Functional_Area  \\\n",
       "0  Accounts   ,     Finance   ,     Tax   ,     C...   \n",
       "1  Sales   ,     Retail   ,     Business Development   \n",
       "2  Production   ,     Manufacturing   ,     Maint...   \n",
       "3  Production   ,     Manufacturing   ,     Maint...   \n",
       "4  Executive Assistant   ,     Front Office   ,  ...   \n",
       "\n",
       "                          Role_Category  \\\n",
       "0                              Accounts   \n",
       "1                         Channel Sales   \n",
       "2  Production/Manufacturing/Maintenance   \n",
       "3  Production/Manufacturing/Maintenance   \n",
       "4                                 Other   \n",
       "\n",
       "                                   Design_Role  \\\n",
       "0                Accounts Executive/Accountant   \n",
       "1                    Sales Executive / Officer   \n",
       "2  Quality Assurance/Quality Control Executive   \n",
       "3  Quality Assurance/Quality Control Executive   \n",
       "4             Stenographer/Data Entry Operator   \n",
       "\n",
       "                                          Key_Skills  \\\n",
       "0  accounting,finance,banking,deposits,Hindi Typi...   \n",
       "1  B2C Sales,Dealer Management,Channel Sales,Dist...   \n",
       "2  Formulation Development,SVP,injectable,oncolog...   \n",
       "3  Formulation Development,SVP,injectable,oncolog...   \n",
       "4  Primary Sales,MIS Preparation,Management infor...   \n",
       "\n",
       "                                    Skill_Experience  \\\n",
       "0  . Monitoring data management to keep accurate ...   \n",
       "1          Please refer to the Job description above   \n",
       "2  We are looking for a Male candidate with minim...   \n",
       "3  We are looking for a Male candidate with minim...   \n",
       "4  *Any Graduate or Post Graduate with previous w...   \n",
       "\n",
       "                                                  UG  \\\n",
       "0                  Any Graduate - Any Specialization   \n",
       "1  B.Tech/B.E. - Any Specialization, B.Sc - Any S...   \n",
       "2                                B.Pharma - Pharmacy   \n",
       "3                                B.Pharma - Pharmacy   \n",
       "4                  Any Graduate - Any Specialization   \n",
       "\n",
       "                                      PG               Doctorate  \n",
       "0  Any Postgraduate - Any Specialization  Doctorate Not Required  \n",
       "1                                                                 \n",
       "2                    M.Pharma - Pharmacy                          \n",
       "3                    M.Pharma - Pharmacy                          \n",
       "4           Post Graduation Not Required                          "
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apnd_dfs20.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Job_Link            https://www.naukri.com/job-listings-CTO-Saas-F...\n",
       "Job_Title                                                         CTO\n",
       "Company_Name                            Saas Force Consulting Pvt Ltd\n",
       "Experience                                                15 - 18 yrs\n",
       "Location                                                        Noida\n",
       "SalaryI                                    25,00,000 - 35,00,000 P.A.\n",
       "Num_Openings                                              Openings: 1\n",
       "Job_Post                                           Posted 22 days ago\n",
       "Job_Application                                                   832\n",
       "Job_View                                                        2000+\n",
       "Salary                                INR  25,00,000 - 35,00,000 P.A.\n",
       "Industry                          IT-Software  /    Software Services\n",
       "Functional_Area     IT Software - Application Programming   ,     ...\n",
       "Role_Category                                       Senior Management\n",
       "Design_Role                             Head/VP/GM-Technology(IT)/CTO\n",
       "Key_Skills          Sales,Salesforce,Software Project,Enterprise A...\n",
       "Skill_Experience            Please refer to the Job description above\n",
       "UG                                  Any Graduate - Any Specialization\n",
       "PG                  MBA/PGDM - Any Specialization, M.Tech - Any Sp...\n",
       "Doctorate                                      Doctorate Not Required\n",
       "Name: 500, dtype: object"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apnd_dfs20.loc[500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-292-3242d5f20c76>, line 45)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-292-3242d5f20c76>\"\u001b[0;36m, line \u001b[0;32m45\u001b[0m\n\u001b[0;31m    df = OrderedDict({'Job_Link':job_url, 'Job_Title':job_title, 'Company_Name':company_name, 'Experience':experience, 'Location':location, 'SalaryI':salary,\u001b[0m\n\u001b[0m     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Job page scrapper in a function\n",
    "def job_page_scrapper(url):\n",
    "    job_response = requests.get(url)\n",
    "    job_page = job_response.text\n",
    "    job_soup = BeautifulSoup(job_page, \"html.parser\")\n",
    "    # get one dataframe with all the links and response so that we can later check from which link we are not able to get data\n",
    "    jdf = OrderedDict({\"Job_Link\":job_url, \"Response\":str(job_response)})\n",
    "    job_links_df = job_links_df.append(jdf,ignore_index=True)\n",
    "    try:\n",
    "        job_title = job_soup.find(\"h1\", {\"itemprop\":\"title\"}).getText().strip()\n",
    "        company_name = job_soup.find(\"a\",{\"itemprop\":\"hiringOrganization\"}).getText().strip()\n",
    "        experience = job_soup.find(\"span\",{\"itemprop\":\"experienceRequirements\"}).getText().strip()\n",
    "        location = job_soup.find(\"div\",{\"class\":\"loc\"}).getText().strip()\n",
    "        salary = job_soup.find(\"span\",{\"class\":\"sal\"}).getText().strip()\n",
    "        #openings = job_soup.find(\"div\",{\"class\":\"sumFoot\"}).find_all(\"span\")\n",
    "        #openings\n",
    "        num_openings = \"\"\n",
    "        job_post = \"\"\n",
    "        for x in job_soup.find(\"div\",{\"class\":\"sumFoot\"}).find_all(\"span\"):\n",
    "            if \"Openings\" in x.text.strip():\n",
    "                num_openings = x.text.strip()\n",
    "            if \"Posted\" in x.text.strip():\n",
    "                job_post = x.text.strip()\n",
    "        job_application = job_soup.find(\"span\",{\"class\":\"jApplys\"}).find(\"strong\").getText().strip()\n",
    "        job_view = job_soup.find(\"span\",{\"class\":\"jViews\"}).find(\"strong\").getText().strip()\n",
    "        job_description = job_soup.find(\"ul\",{\"itemprop\":\"description\"}).getText().strip()\n",
    "        # description labels (other informations about the job)\n",
    "        #for x in job_soup.find(\"div\",{\"class\":\"jDisc mt20\"}).contents:\n",
    "        #    if len(str(x).replace(' ',''))!=0 :\n",
    "        #        print(x.getText().split(':')[-1].strip())\n",
    "        other_info = [x.getText().split(':')[-1].strip() for x in job_soup.find(\"div\",{\"class\":\"jDisc mt20\"}).contents if len(str(x).replace(' ',''))!=0]\n",
    "        other_info_label = {labels: other_info for labels, other_info in zip(labels, other_info)}\n",
    "        key_skills = ','.join(job_soup.find(\"div\",{\"class\":\"ksTags\"}).getText().split(\"  \"))[1:]\n",
    "        skill_experience = job_soup.find(\"ul\",{\"class\":\"listing mt15\"}).getText().strip()\n",
    "        # putting the education information\n",
    "        education = [x.getText().split(':') for x in job_soup.find(\"div\",{\"itemprop\":\"educationRequirements\"}).contents if len(str(x).replace(' ',''))!=0]\n",
    "        education_info = {edu_label.strip(): education.strip() for edu_label, education in education}\n",
    "        for l in edu_labels:\n",
    "            if l not in education_info.keys():\n",
    "                education_info[l] = \"\"\n",
    "        # recruiter information\n",
    "        # This is inside a javascript button : BeautifulSoup is HTML parser: For this need SELENIUM\n",
    "    #except AttributeError:\n",
    "    #    continue\n",
    "    df = OrderedDict({'Job_Link':job_url, 'Job_Title':job_title, 'Company_Name':company_name, 'Experience':experience, 'Location':location, 'SalaryI':salary, \n",
    "                      'Num_Openings':num_openings, 'Job_Post':job_post, 'Job_Application':job_application, 'Job_View':job_view, 'Key_Skills':key_skills, \n",
    "                      'Skill_Experience':skill_experience})\n",
    "    df.update(other_info_label)\n",
    "    df.update(education_info)\n",
    "    job_df = job_df.append(df,ignore_index=True)\n",
    "    print(job_df.shape)\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    0.278217\n",
       "b   -0.418892\n",
       "c   -0.223468\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "df = pd.Series(np.random.randn(3), index=[\"a\",\"b\",\"c\"])\n",
    "df.to_frame()\n",
    "c_n = [\"value\"]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'AA_Desktop/2015-CS109_Harvard/Own_notes _n_programsdata/data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-f5b6521096e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"AA_Desktop/2015-CS109_Harvard/Own_notes _n_programsdata/data.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mC:\\Users\\Ripu\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path, index, sep, na_rep, float_format, header, index_label, mode, encoding, date_format, decimal)\u001b[0m\n\u001b[1;32m   2621\u001b[0m                            \u001b[0mindex_label\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindex_label\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2622\u001b[0m                            \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdate_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdate_format\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2623\u001b[0;31m                            decimal=decimal)\n\u001b[0m\u001b[1;32m   2624\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2625\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Ripu\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, tupleize_cols, date_format, doublequote, escapechar, decimal)\u001b[0m\n\u001b[1;32m   1381\u001b[0m                                      \u001b[0mdoublequote\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdoublequote\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1382\u001b[0m                                      escapechar=escapechar, decimal=decimal)\n\u001b[0;32m-> 1383\u001b[0;31m         \u001b[0mformatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1384\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1385\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Ripu\\Anaconda3\\lib\\site-packages\\pandas\\formats\\format.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1458\u001b[0m             f = _get_handle(self.path_or_buf, self.mode,\n\u001b[1;32m   1459\u001b[0m                             \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1460\u001b[0;31m                             compression=self.compression)\n\u001b[0m\u001b[1;32m   1461\u001b[0m             \u001b[0mclose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1462\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Ripu\\Anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36m_get_handle\u001b[0;34m(path, mode, encoding, compression, memory_map)\u001b[0m\n\u001b[1;32m    330\u001b[0m                 \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m                 \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'replace'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'AA_Desktop/2015-CS109_Harvard/Own_notes _n_programsdata/data.csv'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "df.to_csv(\"AA_Desktop/2015-CS109_Harvard/Own_notes _n_programsdata/data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1, 2, 3, 4]\n",
    "ab = pd.DataFrame(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0\n",
       "0  1\n",
       "1  2\n",
       "2  3\n",
       "3  4"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ab.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ab.to_csv(\"data/abcd.csv\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
